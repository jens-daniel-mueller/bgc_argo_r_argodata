<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="David Stappard, Pasqualina Vonlanthen &amp; Jens Daniel Müller" />


<title>Load BGC-Argo Data</title>

<script src="site_libs/header-attrs-2.18/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">bgc_argo_r_argodata</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Load data
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="load_argo.html">BGC-Argo</a>
    </li>
    <li>
      <a href="load_argo_core.html">Core-Argo</a>
    </li>
    <li>
      <a href="load_argo_clim_pH_ucsd.html">Argo pH Climatology</a>
    </li>
    <li>
      <a href="load_argo_clim_temp_csio.html">Argo Temperature Climatology</a>
    </li>
    <li>
      <a href="load_broullon_DIC_TA_clim.html">Broullón DIC/TA Climatology</a>
    </li>
    <li>
      <a href="load_OceanSODA.html">OceanSODA</a>
    </li>
    <li>
      <a href="load_biomes.html">Biomes</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Data coverage
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="coverage_timeseries.html">Time series</a>
    </li>
    <li>
      <a href="coverage_maps.html">Maps</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Data
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="argo_ph.html">Argo pH</a>
    </li>
    <li>
      <a href="argo_oxygen.html">Argo Oxygen</a>
    </li>
    <li>
      <a href="argo_temp.html">Argo BGC-SST</a>
    </li>
    <li>
      <a href="argo_temp_core.html">Argo Core-SST</a>
    </li>
    <li>
      <a href="oceanSODA_argo_pH.html">OceanSODA-Argo pH</a>
    </li>
    <li>
      <a href="oceanSODA_argo_temp.html">OceanSODA-BGC-Argo SST</a>
    </li>
    <li>
      <a href="extreme_pH.html">Extreme pH Profiles</a>
    </li>
    <li>
      <a href="extreme_temp.html">Extreme BGC-Temperature Profiles</a>
    </li>
    <li>
      <a href="extreme_temp_core.html">Extreme Core-Temperature Profiles</a>
    </li>
    <li>
      <a href="extreme_compound.html">Compound extremes</a>
    </li>
    <li>
      <a href="variability_temp.html">Argo Temperature Variability</a>
    </li>
    <li>
      <a href="variability_pH.html">Argo pH variability</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata">
    <span class="fa fa-github"></span>
     
    Code
  </a>
</li>
<li>
  <a href="https://jens-daniel-mueller.github.io/">
    <span class="fa fa-home"></span>
     
    Jens home
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Load BGC-Argo Data</h1>
<h4 class="author">David Stappard, Pasqualina Vonlanthen &amp; Jens
Daniel Müller</h4>
<h4 class="date">27 October, 2023</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2023-10-27
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>bgc_argo_r_argodata/</code> <span
class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.0). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20211008code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20211008)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20211008code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20211008)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomjensdanielmuellerbgcargorargodatatree8fac6bbbe1f139c134af08cf1309a8bd4dff4602targetblank8fac6bba">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/tree/8fac6bbbe1f139c134af08cf1309a8bd4dff4602" target="_blank">8fac6bb</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomjensdanielmuellerbgcargorargodatatree8fac6bbbe1f139c134af08cf1309a8bd4dff4602targetblank8fac6bba"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/tree/8fac6bbbe1f139c134af08cf1309a8bd4dff4602" target="_blank">8fac6bb</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    output/

Untracked files:
    Untracked:  code/pH_align_climatology.Rmd
    Untracked:  code/temp_align_climatology.Rmd

Unstaged changes:
    Modified:   analysis/load_argo_clim_pH_ucsd.Rmd
    Modified:   code/Workflowr_project_managment.R
    Modified:   code/start_background_job.R
    Modified:   code/start_background_job_bgc_load.R

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown (<code>analysis/load_argo.Rmd</code>) and HTML
(<code>docs/load_argo.html</code>) files. If you’ve configured a remote
Git repository (see <code>?wflow_git_remote</code>), click on the
hyperlinks in the table below to view the files as they were in that
past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/8fac6bbbe1f139c134af08cf1309a8bd4dff4602/analysis/load_argo.Rmd" target="_blank">8fac6bb</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-27
</td>
<td>
maintaining file_id in all datasets
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/jens-daniel-mueller/bgc_argo_r_argodata/93b4545275c9570673e22da1f9b3f2eec899c55a/docs/load_argo.html" target="_blank">93b4545</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-18
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/7af09d6b8ed99c958f72a59e9d06ca2e05027cda/analysis/load_argo.Rmd" target="_blank">7af09d6</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-18
</td>
<td>
standard range v climatology, season order resolved and count labels to
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/8edb9f4b9d60a02880bfcc182c0b669f8e4256b3/analysis/load_argo.Rmd" target="_blank">8edb9f4</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-17
</td>
<td>
BGC load process aligned to core load. Associated changes to pH and
oxygen analysis.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/jens-daniel-mueller/bgc_argo_r_argodata/db6fc8a5168735f4ec56926e289dd1a9caa57e48/docs/load_argo.html" target="_blank">db6fc8a</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-17
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/ed8e997471a36ccc07a26310a667b6273a1d3acf/analysis/load_argo.Rmd" target="_blank">ed8e997</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-17
</td>
<td>
Revised version of BGC load to match core load process
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/jens-daniel-mueller/bgc_argo_r_argodata/0ee3427d316a537386be98d1fa27a78edab896e4/docs/load_argo.html" target="_blank">0ee3427</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/82d027d42dcf74fb4aca12113bb612baad1a2722/analysis/load_argo.Rmd" target="_blank">82d027d</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-16
</td>
<td>
Revised version of BGC load to match core load process
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/3f6800f3dc7640ac1eff95d77482c18a5d98296c/analysis/load_argo.Rmd" target="_blank">3f6800f</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-14
</td>
<td>
Changes to core load to create a simple qc flag summary
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/fad0b84b8089fdc1bfa5049d929692bcc70391fa/analysis/load_argo.Rmd" target="_blank">fad0b84</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-04
</td>
<td>
Changed BGC Argo location folders
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/jens-daniel-mueller/bgc_argo_r_argodata/7b3d8c513f8186b81813c5d82edbea3f8f2beffd/docs/load_argo.html" target="_blank">7b3d8c5</a>
</td>
<td>
pasqualina-vonlanthendinenna
</td>
<td>
2022-08-29
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/8e815707d1fdc0b9ee057445b0eff0fac2b9376f/analysis/load_argo.Rmd" target="_blank">8e81570</a>
</td>
<td>
pasqualina-vonlanthendinenna
</td>
<td>
2022-08-29
</td>
<td>
load and add in core-argo data (1 month)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/jens-daniel-mueller/bgc_argo_r_argodata/bdd516daab19b4b6de5bea8181dd508383613b08/docs/load_argo.html" target="_blank">bdd516d</a>
</td>
<td>
pasqualina-vonlanthendinenna
</td>
<td>
2022-05-23
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/b41e65fd914055dbe6a0423cc44d59a8e8dcc8ba/analysis/load_argo.Rmd" target="_blank">b41e65f</a>
</td>
<td>
pasqualina-vonlanthendinenna
</td>
<td>
2022-05-23
</td>
<td>
recreate data in bgc_argo_preprocessed_data
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/jens-daniel-mueller/bgc_argo_r_argodata/dfe89d7b8e7a115750b3d64e7f8729619f9177d1/docs/load_argo.html" target="_blank">dfe89d7</a>
</td>
<td>
jens-daniel-mueller
</td>
<td>
2022-05-12
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/f29dafc06bbd5eb840c2b34b8bdabb88668f45e1/analysis/load_argo.Rmd" target="_blank">f29dafc</a>
</td>
<td>
jens-daniel-mueller
</td>
<td>
2022-05-11
</td>
<td>
manual commit
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="task" class="section level1">
<h1>Task</h1>
<p>Load BGC data for analysis</p>
<div id="set-load-options" class="section level2">
<h2>Set load options</h2>
<p>Determine if files are refreshed from dac or cache directory is used.
Are metadata, temperature, salinity and BGC property year files renewed?
Are the consolidated all year files created from the individual year
files?</p>
<pre class="r"><code># opt_refresh_cache
#   FALSE = do not refresh cache.
#   TRUE  = refresh cache. (any none zero value will force a refresh)
opt_refresh_cache = FALSE

# opt_min_year and opt_max_year
#   year to be refreshed are set by opt_min_year and opt_max_year
opt_min_year = 2013
opt_max_year = 2023

# opt_review_mode
# if set (1) the processing will take place in a sub-directory opt_review_dir and only process 10 days of profiles per year to reduce size
# of output and processing time
opt_review_mode = FALSE
opt_review_dir = &quot;/review_mode&quot;

#if (opt_review_mode) {
#  path_argo_preprocessed &lt;- paste0(path_argo_core, &quot;/preprocessed_data&quot;, opt_review_dir)
#}
  
# opt_qc_only
# Avoids reprocessing files and ensures qc summary plots are created from a previous run!
#   FALSE = carry out reprocessing based on options set above and create QC summaries.
#   TRUE  = do NOT reprocessing files and just create QC summaries from previous loads.
opt_qc_only = FALSE

# opt_n_prof_sel
# The selection criteria that is used against n_prof, here set to 1
# Description of n_prof usage is provided at https://argo.ucsd.edu/data/data-faq/version-3-profile-files/ the next two lines are from that page.
#     The main Argo CTD profile is stored in N_PROF=1. All other parameters (including biogeochemical parameters) that are measured 
#     with the same vertical sampling scheme and at the same location and time as the main Argo CTD profile are also stored in N_PROF=1.
opt_n_prof_sel = 1</code></pre>
</div>
<div id="set-cache-directory" class="section level2">
<h2>Set cache directory</h2>
<p>Directory where the core-Argo profile files are stored. Either use
the cached files or force a refresh from dac (long process)</p>
<pre class="r"><code>if (!opt_qc_only) {

  # set cache directory
  argo_set_cache_dir(cache_dir = path_argo)
  
  # check cache directory
  argo_cache_dir()
  
  # check argo mirror
  argo_mirror()
  
  # age argument: age of the cached files to update in hours (Inf means always use the cached file, and -Inf means always download from the server) 
  # ex: max_global_cache_age = 5 updates files that have been in the cache for more than 5 hours, max_global_cache_age = 0.5 updates 
  # files that have been in the cache for more than 30 minutes, etc.
  if (opt_refresh_cache){
    argo_update_global(max_global_cache_age = -Inf)  
    argo_update_data(max_data_cache_age = -Inf)
  } else {
    argo_update_global(max_global_cache_age = Inf)  
    argo_update_data(max_data_cache_age = Inf)
  }
}</code></pre>
</div>
<div id="data-load" class="section level2">
<h2>Data Load</h2>
<p>Builds yearly files for temperature, salinity, BGC properties and
metadata that can be consolidated in the next code chunk
(consolidate_into_allyears). Load in the synthetic (merged core and bgc)
index files (uses the data stored on the ifremer server by default),
keeping only delayed-mode data.</p>
<div id="file-types" class="section level3">
<h3>File Types</h3>
<p>A core-Argo profile contains the CTD sensor parameters (pressure,
temperature, salinity) that are measured with the same vertical sampling
scheme and at the same location and time. Additional parameters from
other sensors are stored in the b-Argo profile files.</p>
<p>A b-Argo profile contains all the parameters from a float, except the
core-Argo parameters temperature, pressure, and salinity. A float that
performs only CTD measurements does not have a b-Argo file. The vertical
level <code>PRES</code> is the simple and unambiguous link between the
parameters in the core-Argo and b-Argo files. The same <code>PRES</code>
is recorded in the core-Argo and b-Argo files. PRES is the only
parameter duplicated in core-Argo and b-Argo profile files.</p>
<p>To facilitate the use of BGC-Argo data, the regional data centers
merge each b-Argo file with its corresponding core-Argo file into one
synthetic (s-Argo) file. The goal of a simplified s-Argo file is to
co-locate as many BGC observations as possible while preserving the
character of the sampling pattern, i.e., sample interval, number of
samples, and approximate pressure locations. Data come from the single
c- and b-Argo files. The synthetic pressure axis is constructed from the
BGC sampling levels from each cycle. This means that there is no fixed
vertical grid for all floats and all cycles.</p>
<p>The co-location takes different vertical attachments of BGC sensors
into account by displacing the pressure location, which is not the case
in the c- and b-files. The single-cycle s–file profiles contain all the
c-file parameter observations in their original location and
resolution.</p>
<p>The adjusted pressure parameter (<code>pres_adjusted</code>) is only
available in the core- and s-Argo profile files. The variables
<code>profile_pres_qc</code>, <code>pres_adjusted</code>, and
<code>pres_adjusted_error</code>, are not duplicated in the b-Argo
files.</p>
</div>
<div id="data-modes" class="section level3">
<h3>Data Modes</h3>
<p>Delayed-mode data are denoted by <code>data_mode = 'D'</code>, and
are quality-checked by PIs, who apply any necessary adjustments. For the
core CTD data, delayed-mode data is generally available 12 months after
the transmission of raw data, because the raw data is usually of good
quality. Their delayed-mode assessment involves evaluation of the
long-term sensor stability, which typically requires a float record of
12 months. Incorrect QC flag attribution and erroneous raw data not
flagged during real-time procedures are corrected in delayed-mode.</p>
<p>Delayed-mode BGC data may be available as early as 5-6 cycles after
initial data transmission as the raw data are typically unfit for
scientific usage. Adjustments significantly increase the accuracy of
these data. In b- and s-Argo profile files, the variable
<code>parameter_data_mode</code> indicates the mode of each parameter.
Biogeochemical parameters in the same file may receive their
delayed-mode adjustments at different times.</p>
<p><em>Synthetic files info: <a
href="https://archimer.ifremer.fr/doc/00445/55637/80863.pdf"
class="uri">https://archimer.ifremer.fr/doc/00445/55637/80863.pdf</a></em></p>
<p><em>Argo User Manual: <a
href="https://archimer.ifremer.fr/doc/00187/29825/86414.pdf"
class="uri">https://archimer.ifremer.fr/doc/00187/29825/86414.pdf</a></em></p>
</div>
</div>
<div id="load-index" class="section level2">
<h2>Load Index</h2>
<p>Load index file that forms the basis of subsequent sections that load
data and metadata</p>
<pre class="r"><code>if (!opt_qc_only) {

      # if working in reiew mode only consider first 10 days of opt_max_year
      if (opt_review_mode) {
        bgc_index &lt;- argo_global_synthetic_prof() %&gt;% 
          argo_filter_data_mode(data_mode = &#39;delayed&#39;) %&gt;% 
          argo_filter_date(date_min = paste0(opt_max_year, &quot;-01-01&quot;),
                           date_max = paste0(opt_max_year, &quot;-01-10&quot;))
      } else {
        bgc_index &lt;- argo_global_synthetic_prof() %&gt;% 
          argo_filter_data_mode(data_mode = &#39;delayed&#39;) %&gt;% 
          argo_filter_date(date_min = paste0(opt_min_year, &quot;-01-01&quot;),
                           date_max = paste0(opt_max_year, &quot;-12-31&quot;))
      }

}</code></pre>
</div>
<div id="load-data" class="section level2">
<h2>Load data</h2>
<p>Read in the adjusted bgc and core variables corresponding to the
index files downloaded above, with their quality control flags. (can
take a while)</p>
<pre class="r"><code>if (!opt_qc_only) {

  bgc_data &lt;- argo_prof_levels(
    path = bgc_index,
    vars =
      c(
        &#39;PRES_ADJUSTED&#39;,
        &#39;PRES_ADJUSTED_QC&#39;,
        &#39;PRES_ADJUSTED_ERROR&#39;,
        &#39;PSAL_ADJUSTED&#39;,
        &#39;PSAL_ADJUSTED_QC&#39;,
        &#39;PSAL_ADJUSTED_ERROR&#39;,
        &#39;TEMP_ADJUSTED&#39;,
        &#39;TEMP_ADJUSTED_QC&#39;,
        &#39;TEMP_ADJUSTED_ERROR&#39;,
        &#39;DOXY_ADJUSTED&#39;,
        &#39;DOXY_ADJUSTED_QC&#39;,
        &#39;DOXY_ADJUSTED_ERROR&#39;,
        &#39;NITRATE_ADJUSTED&#39;,
        &#39;NITRATE_ADJUSTED_QC&#39;,
        &#39;NITRATE_ADJUSTED_ERROR&#39;,
        &#39;PH_IN_SITU_TOTAL_ADJUSTED&#39;,
        &#39;PH_IN_SITU_TOTAL_ADJUSTED_QC&#39;,
        &#39;PH_IN_SITU_TOTAL_ADJUSTED_ERROR&#39;
      ),
    quiet = TRUE
  ) 
  # read in the profiles (takes a while)

  # see option section above for rational of why we only want n_prof = 1 profiles.
  # Note as working with symthetic profiles has no impact.
  bgc_data &lt;- bgc_data %&gt;%
  filter(n_prof == opt_n_prof_sel)

}</code></pre>
</div>
<div id="read-meta-data" class="section level2">
<h2>Read meta data</h2>
<p>Read in the corresponding metadata:</p>
<pre class="r"><code>if (!opt_qc_only) {

  bgc_metadata &lt;- argo_prof_prof(path = bgc_index)

  # see option section above for rational of why we only want n_prof = 1 profiles
  # Note as working with symthetic profiles has no impact.
  bgc_metadata &lt;- bgc_metadata %&gt;%
  filter(n_prof == opt_n_prof_sel)

  # Select just the columns we are interested in
  bgc_metadata &lt;- bgc_metadata %&gt;%
    select (
      file,
      date,
      latitude,
      longitude,
      platform_number, 
      cycle_number,
      position_qc,
      profile_pres_qc,
      profile_temp_qc,
      profile_psal_qc,
      profile_doxy_qc,
      profile_nitrate_qc,
      profile_ph_in_situ_total_qc
    )

}</code></pre>
</div>
<div id="join-data" class="section level2">
<h2>Join data</h2>
<p>Join the metadata and data together into one dataset</p>
<pre class="r"><code>if (!opt_qc_only) {

  bgc_merge &lt;- full_join(bgc_data, bgc_metadata)
  
  bgc_merge &lt;- bgc_merge %&gt;%
    rename(lon = longitude,
           lat = latitude) %&gt;%
    mutate(lon = if_else(lon &lt; 20, lon + 360, lon)) %&gt;%
    mutate(
      lat = cut(lat, seq(-90, 90, 1), seq(-89.5, 89.5, 1)),
      lat = as.numeric(as.character(lat)),
      lon = cut(lon, seq(20, 380, 1), seq(20.5, 379.5, 1)),
      lon = as.numeric(as.character(lon))
    ) %&gt;%
    mutate(depth = gsw_z_from_p(pres_adjusted, latitude =  lat) * -1.0,
           .before = pres_adjusted)
  
  # Harmonise metadata
  bgc_metadata &lt;- bgc_metadata %&gt;%
    rename(lon = longitude,
           lat = latitude) %&gt;%
    mutate(lon = if_else(lon &lt; 20, lon + 360, lon)) %&gt;%
    mutate(
      lat = cut(lat, seq(-90, 90, 1), seq(-89.5, 89.5, 1)),
      lat = as.numeric(as.character(lat)),
      lon = cut(lon, seq(20, 380, 1), seq(20.5, 379.5, 1)),
      lon = as.numeric(as.character(lon))
  )
  
  # Create fileid dataframe and link back to merge and metadata
  bgc_fileid &lt;- unique(bgc_merge$file)
  bgc_fileid &lt;- tibble(bgc_fileid)
  bgc_fileid &lt;- bgc_fileid %&gt;% select (file = bgc_fileid)
  bgc_fileid &lt;- tibble::rowid_to_column(bgc_fileid, &quot;file_id&quot;)

  # Change metadate, data and merge to have file_id
  bgc_metadata &lt;- full_join(bgc_metadata, bgc_fileid)
  bgc_metadata &lt;- bgc_metadata %&gt;%
                    select(-c(file))
  bgc_merge &lt;- full_join(bgc_merge, bgc_fileid)
  bgc_merge &lt;- bgc_merge %&gt;%
                    select(-c(file))
  bgc_data &lt;- full_join(bgc_data, bgc_fileid)
  bgc_data &lt;- bgc_data %&gt;%
                    select(-c(file))

  # Summary measurement QC data
  bgc_data_qc &lt;- bgc_merge %&gt;%
    select (
      &#39;date&#39;,
      &#39;pres_adjusted_qc&#39;,
      &#39;psal_adjusted_qc&#39;,
      &#39;temp_adjusted_qc&#39;,
      &#39;doxy_adjusted_qc&#39;,
      &#39;nitrate_adjusted_qc&#39;,
      &#39;ph_in_situ_total_adjusted_qc&#39;
            ) %&gt;%
    mutate(year = year(date),
           .after = date)
  
  # Create the summary file that is used later for qc analysis
  bgc_measure_summary &lt;- bgc_data_qc %&gt;% 
                                 group_by(year, measure_order = 1, measure = &quot;Pressure&quot;, measure_qc = pres_adjusted_qc) %&gt;% 
                                 summarise(count_measure = n())
  bgc_measure_summary &lt;- rbind(bgc_measure_summary, bgc_data_qc %&gt;% 
                                 group_by(year, measure_order = 2, measure = &quot;Temperature&quot;, measure_qc = temp_adjusted_qc) %&gt;% 
                                 summarise(count_measure = n()))
  bgc_measure_summary &lt;- rbind(bgc_measure_summary, bgc_data_qc %&gt;% 
                                 group_by(year, measure_order = 3, measure = &quot;Salinity&quot;, measure_qc = psal_adjusted_qc) %&gt;% 
                                 summarise(count_measure = n()))
  bgc_measure_summary &lt;- rbind(bgc_measure_summary, bgc_data_qc %&gt;% 
                                 group_by(year, measure_order = 4, measure = &quot;pH&quot;, measure_qc = ph_in_situ_total_adjusted_qc) %&gt;% 
                                 summarise(count_measure = n()))
  bgc_measure_summary &lt;- rbind(bgc_measure_summary, bgc_data_qc %&gt;% 
                                 group_by(year, measure_order = 5, measure = &quot;Oxygen&quot;, measure_qc = doxy_adjusted_qc) %&gt;% 
                                 summarise(count_measure = n()))
  bgc_measure_summary &lt;- rbind(bgc_measure_summary, bgc_data_qc %&gt;% 
                                 group_by(year, measure_order = 6, measure = &quot;Nitrate&quot;, measure_qc = nitrate_adjusted_qc) %&gt;% 
                                 summarise(count_measure = n()))
  rm(bgc_data_qc)
  bgc_measure_summary %&gt;%
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_measure_summary.rds&quot;))
    
}</code></pre>
</div>
<div id="ph-data" class="section level2">
<h2>pH data</h2>
<p>All pH data from BGC floats with QC flag 1 (good data) ph_surface: pH
data in the top 20 m of the watercolumn with QC flag 1</p>
<pre class="r"><code>if (!opt_qc_only) {

  bgc_merge_pH_qc_1 &lt;- bgc_merge %&gt;%
    filter(ph_in_situ_total_adjusted_qc == &#39;1&#39;) %&gt;%
    select(
      file_id,
      date,
      lat,
      lon,
      depth,
      psal_adjusted,
      temp_adjusted,
      temp_adjusted_qc,
      ph_in_situ_total_adjusted,
      ph_in_situ_total_adjusted_qc,
      platform_number,
      cycle_number,
      profile_ph_in_situ_total_qc,
      profile_temp_qc
    )
  
  # create a dataframe of full pH data (only good data) with corresponding CTD and metadata, in a 1x1º longitude/latitude grid
  ph_merge_1x1 &lt;- bgc_merge %&gt;%
    select(
      -c(doxy_adjusted:nitrate_adjusted_error),
      -c(profile_doxy_qc, profile_nitrate_qc)
    ) %&gt;%
    filter(ph_in_situ_total_adjusted_qc == &#39;1&#39;) %&gt;%
    mutate(year = year(date),
           month = month(date),
           .after = n_prof)
  
  
  # create a dataframe of pH data in the surface ocean (upper 20 m of the watercolumn), in a 1x1º longitude/latitude grid
  ph_surface_1x1 &lt;- ph_merge_1x1 %&gt;%
    filter(between(depth, 0, 20))
  
  # create a dataframe of pH for the surface ocean (upper 20 m of the watercolumn) in a 2x2º longitude/latitude grid
  ph_surface_2x2 &lt;- ph_surface_1x1 %&gt;%
    mutate(
      lat = cut(lat, seq(-90, 90, 2), seq(-89, 89, 2)),
      lat = as.numeric(as.character(lat)),
      lon = cut(lon, seq(20, 380, 2), seq(21, 379, 2)),
      lon = as.numeric(as.character(lon))
    )   # regrid into 2x2º grid

}</code></pre>
</div>
<div id="temperature-data" class="section level2">
<h2>Temperature data</h2>
<p>All temperature data from BGC floats with QC flag 1</p>
<pre class="r"><code>if (!opt_qc_only) {

  # Include bgc_merge_temp_qc == 8 as this is as good as 1 and matches the BGC data points
  bgc_merge_temp_qc_1 &lt;- bgc_merge %&gt;% 
    filter(temp_adjusted_qc == &#39;1&#39; | temp_adjusted_qc == &#39;8&#39;) %&gt;% 
    select(file_id, date, lat, lon, 
           depth, temp_adjusted,
           platform_number, cycle_number,
           temp_adjusted_qc, ph_in_situ_total_adjusted_qc,
           profile_temp_qc,
           profile_ph_in_situ_total_qc)
}</code></pre>
</div>
<div id="qc-flag-a-and-b-temperature-data" class="section level2">
<h2>QC flag A and B temperature data</h2>
<p>BGC-temperature data with QC flags A and B, irrespective of whether a
corresponding pH measurement exists</p>
<pre class="r"><code>if (!opt_qc_only) {
  
  bgc_merge_temp_AB &lt;- bgc_merge %&gt;% 
    filter(profile_temp_qc == &#39;A&#39; | profile_temp_qc == &#39;B&#39;) %&gt;% 
    filter(temp_adjusted_qc == &#39;1&#39; | temp_adjusted_qc == &#39;8&#39;) %&gt;% 
    select(file_id, date, lat, lon,
           depth, temp_adjusted, temp_adjusted_qc,
           platform_number, cycle_number,
           profile_temp_qc)

}</code></pre>
</div>
<div id="qc-flag-a-and-b-ph-temperature-data" class="section level2">
<h2>QC flag A and B pH &amp; temperature data</h2>
<p>pH and temperature data from floats where both variables have full
profiles with QC flag A</p>
<pre class="r"><code>if (!opt_qc_only) {

  # create a dataframe with temperature and pH profile flags A and B only 
  # keep only temperature observations where good pH data exists: 
  
  # using only complete profiles, and temperature data where pH measurements exist:
  
  bgc_merge_flag_AB &lt;- bgc_merge %&gt;%
    filter(profile_ph_in_situ_total_qc %in% c(&#39;A&#39;, &#39;B&#39;),
           profile_temp_qc %in% c(&#39;A&#39;, &#39;B&#39;)) %&gt;%
    select(file_id, depth,
           temp_adjusted:temp_adjusted_error,
           ph_in_situ_total_adjusted:ph_in_situ_total_adjusted_error,
           platform_number,
           cycle_number,
           date,
           lat, lon,
           profile_temp_qc,
          profile_ph_in_situ_total_qc) %&gt;%
    filter(!is.na(ph_in_situ_total_adjusted))
  # no NA temperature values
  # 518 340 total observations 
}</code></pre>
</div>
<div id="qc-flag-1-ph-temperature-data" class="section level2">
<h2>QC flag 1 pH &amp; temperature data</h2>
<p>pH and temperature data where both variables have QC flags 1</p>
<pre class="r"><code>if (!opt_qc_only) {

  # Include bgc_merge_temp_qc == 8 as this is as good as 1 and matches the BGC data points
  bgc_merge_qc_1 &lt;- bgc_merge %&gt;% 
    filter(ph_in_situ_total_adjusted_qc == &#39;1&#39; &amp; (temp_adjusted_qc == &#39;1&#39; | temp_adjusted_qc == &#39;8&#39;)) %&gt;% 
    select(file_id, depth,
           temp_adjusted:temp_adjusted_error,
           ph_in_situ_total_adjusted:ph_in_situ_total_adjusted_error,
           platform_number,
           cycle_number,
           date,
           lat, lon,
           profile_temp_qc,
           profile_ph_in_situ_total_qc)
}</code></pre>
</div>
<div id="write-argo-data-to-files" class="section level2">
<h2>Write Argo data to files</h2>
<pre class="r"><code>if (!opt_qc_only) {

  bgc_index %&gt;%
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_index.rds&quot;))
  
  bgc_data %&gt;%
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_data.rds&quot;))
  
  bgc_merge %&gt;%
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_merge.rds&quot;))
  
  bgc_fileid %&gt;%
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_fileid.rds&quot;))

    bgc_merge_pH_qc_1 %&gt;%
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_merge_pH_qc_1.rds&quot;))
  
  bgc_merge_temp_qc_1 %&gt;% 
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_merge_temp_qc_1.rds&quot;))
  
  bgc_merge_temp_AB %&gt;% 
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_merge_temp_AB.rds&quot;))
  
  bgc_merge_flag_AB %&gt;%
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_merge_flag_AB.rds&quot;))
  
  bgc_merge_qc_1 %&gt;% 
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_merge_qc_1.rds&quot;))
  
  ph_merge_1x1 %&gt;% 
    write_rds(file = paste0(path_argo_preprocessed, &quot;/ph_merge_1x1.rds&quot;))
  
  bgc_metadata %&gt;%
    write_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_metadata.rds&quot;))
  
  ph_surface_1x1 %&gt;% 
    write_rds(file = paste0(path_argo_preprocessed, &quot;/ph_surface_1x1.rds&quot;))
  
  ph_surface_2x2 %&gt;% 
    write_rds(file = paste0(path_argo_preprocessed, &quot;/ph_surface_2x2.rds&quot;))

}</code></pre>
</div>
<div id="qc-summary" class="section level2">
<h2>QC summary</h2>
<div id="profile-qc-flags-a-f" class="section level3">
<h3>profile QC flags (A-F)</h3>
<p>Produce a summary of profile QC flags (A-F)</p>
<pre class="r"><code># Read metadata file and create profile summary table with a count for each year, measurement type and qc option
bgc_metadata &lt;-
read_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_metadata.rds&quot;))
bgc_metadata[&quot;profile_pres_qc&quot;][is.na(bgc_metadata[&quot;profile_pres_qc&quot;])] &lt;- &quot;&quot; 
bgc_metadata[&quot;profile_temp_qc&quot;][is.na(bgc_metadata[&quot;profile_temp_qc&quot;])] &lt;- &quot;&quot; 
bgc_metadata[&quot;profile_psal_qc&quot;][is.na(bgc_metadata[&quot;profile_psal_qc&quot;])] &lt;- &quot;&quot; 
bgc_metadata[&quot;profile_doxy_qc&quot;][is.na(bgc_metadata[&quot;profile_doxy_qc&quot;])] &lt;- &quot;&quot; 
bgc_metadata[&quot;profile_nitrate_qc&quot;][is.na(bgc_metadata[&quot;profile_nitrate_qc&quot;])] &lt;- &quot;&quot; 
bgc_metadata[&quot;profile_ph_in_situ_total_qc&quot;][is.na(bgc_metadata[&quot;profile_ph_in_situ_total_qc&quot;])] &lt;- &quot;&quot; 

bgc_profile_summary &lt;- bgc_metadata %&gt;% 
  filter (profile_temp_qc != &quot;&quot;) %&gt;%
  group_by(
    year = format(date, &quot;%Y&quot;), 
    measure = &quot;Temperature&quot;, 
    measure_order = 2, 
    profile_qc = profile_temp_qc
    ) %&gt;% 
  summarise(
    count_profiles = n()
    )
bgc_profile_summary &lt;- rbind(bgc_profile_summary, 
                              bgc_metadata %&gt;% 
                                filter (profile_ph_in_situ_total_qc != &quot;&quot;) %&gt;%
                                group_by(
                                  year = format(date, &quot;%Y&quot;), 
                                  measure = &quot;pH&quot;, 
                                  measure_order = 4, 
                                  profile_qc = profile_ph_in_situ_total_qc
                                  ) %&gt;% 
                                summarise(
                                  count_profiles = n()
                                  ))
bgc_profile_summary &lt;- rbind(bgc_profile_summary, 
                              bgc_metadata %&gt;% 
                                filter (profile_doxy_qc != &quot;&quot;) %&gt;%
                                group_by(
                                  year = format(date, &quot;%Y&quot;), 
                                  measure = &quot;oxygen&quot;, 
                                  measure_order = 5, 
                                  profile_qc = profile_doxy_qc
                                  ) %&gt;% 
                                summarise(
                                  count_profiles = n()
                                  ))
# modify data frame to prepare for plotting
bgc_profile_summary &lt;- ungroup(bgc_profile_summary)
bgc_profile_summary &lt;- bgc_profile_summary %&gt;% group_by(measure_order)
bgc_profile_summary &lt;- transform(bgc_profile_summary, year = as.numeric(year))

year_min &lt;- min(bgc_profile_summary$year)
year_max &lt;- max(bgc_profile_summary$year)
facet_label &lt;- as_labeller(c(&quot;2&quot;=&quot;Temperature&quot;, &quot;4&quot;=&quot;pH&quot;, &quot;5&quot;=&quot;Oxygen&quot;))
  
# draw plots for the separate parameters
bgc_profile_summary %&gt;%
  ggplot(aes(x = year, y = count_profiles, col = profile_qc, group=profile_qc)) +
          geom_point() +
          geom_line() +
          facet_wrap(~measure_order, labeller = facet_label) +
          scale_x_continuous(breaks = seq(year_min, year_max, 2)) +
          labs(x = &#39;year&#39;, 
               y = &#39;number of profiles&#39;, 
               col = &#39;profile QC flag&#39;,
               title = &#39;Count of profile qc flags by year&#39;)</code></pre>
<p><img src="figure/load_argo.Rmd/QC_summary_profile-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-QC_summary_profile-1">
Past versions of QC_summary_profile-1.png
</button>
</p>
<div id="fig-QC_summary_profile-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/93b4545275c9570673e22da1f9b3f2eec899c55a/docs/figure/load_argo.Rmd/QC_summary_profile-1.png" target="_blank">93b4545</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-18
</td>
</tr>
<tr>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/0ee3427d316a537386be98d1fa27a78edab896e4/docs/figure/load_argo.Rmd/QC_summary_profile-1.png" target="_blank">0ee3427</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-16
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="measurement-qc-flags-1-9" class="section level3">
<h3>measurement QC flags (1-9)</h3>
<p>Produce a summary of current measurement QC flags (1-9)</p>
<pre class="r"><code># Read temp and meta_data
bgc_measure_summary &lt;-
read_rds(file = paste0(path_argo_preprocessed, &quot;/bgc_measure_summary.rds&quot;))
bgc_measure_summary &lt;- ungroup(bgc_measure_summary)

year_min &lt;- min(bgc_measure_summary$year)
year_max &lt;- max(bgc_measure_summary$year)

# draw plots for the separate parameters
bgc_measure_summary %&gt;%
  filter(measure_qc != &quot; &quot; &amp; measure_order %in% c(2, 4, 5)) %&gt;%
  ggplot(aes(x = year, y = count_measure, col = measure_qc, group=measure_qc)) +
          geom_point() +
          geom_line() +
          facet_wrap(~measure_order, labeller = facet_label) +
          scale_x_continuous(breaks = seq(year_min, year_max, 2)) +
          labs(x = &#39;year&#39;, 
               y = &#39;number of measures&#39;, 
               col = &#39;measure QC flag&#39;,
               title = &#39;Count of measure qc flags by year&#39;)</code></pre>
<p><img src="figure/load_argo.Rmd/QC_summary_measure-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-QC_summary_measure-1">
Past versions of QC_summary_measure-1.png
</button>
</p>
<div id="fig-QC_summary_measure-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/93b4545275c9570673e22da1f9b3f2eec899c55a/docs/figure/load_argo.Rmd/QC_summary_measure-1.png" target="_blank">93b4545</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-18
</td>
</tr>
<tr>
<td>
<a href="https://github.com/jens-daniel-mueller/bgc_argo_r_argodata/blob/0ee3427d316a537386be98d1fa27a78edab896e4/docs/figure/load_argo.Rmd/QC_summary_measure-1.png" target="_blank">0ee3427</a>
</td>
<td>
ds2n19
</td>
<td>
2023-10-16
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</div>
<div id="data-set-description" class="section level1">
<h1>Data set description</h1>
<div id="argo-columns" class="section level2">
<h2>Argo Columns</h2>
<p>The resulting bgc_merge dataframe contains:</p>
<ul>
<li><p>the file name (<code>file</code> column)</p></li>
<li><p>the sampling level (<code>n_level</code> column)</p></li>
<li><p>the number of profiles per file (<code>n_prof</code> column; Each
single-cycle synthetic profile has the dimension
<code>n_prof = 1</code>).</p></li>
<li><p>adjusted values for pressure (<code>pres</code>, in dbar),
salinity (<code>psal</code>, in psu), temperature (<code>temp</code>, in
degrees C), dissolved oxygen (<code>doxy</code>, in µmol
kg<sup>-1</sup>), pH (<code>ph_in_situ_total</code>), and nitrate
(<code>nitrate</code>, in µmol kg<sup>-1</sup>)
(<code>parameter_adjusted</code> columns). This column is mandatory, so
if no adjustment was performed (i.e. <code>parameter_adjusted</code>
does not exist), FillValue is inserted (e.g.,
<code>temp_adjusted:FillValue = 99999.f</code>). If the raw value did
not require adjustment in delayed-mode, then
<code>parameter_adjusted</code> = <code>parameter</code>.</p></li>
<li><p>a quality control flag associated with these adjusted values
(<code>parameter_adjusted_qc</code> columns). If an adjusted value does
not exist (e.g., <code>temp_adjusted = 99999.f</code>), then FillValue
is inserted (e.g., <code>temp_adjusted_qc = " "</code>).</p></li>
<li><p>an error estimate on the adjustment of the measurement
(<code>parameter_adjusted_error</code> columns). If no adjusted value
exists (e.g., <code>temp_adjusted = 99999.f</code>), then FillValue is
inserted (e.g., <code>temp_adjusted_error = 99999.f</code>)</p></li>
<li><p>WMO float identifier (<code>platform_number</code>
column)</p></li>
<li><p>name of the project in charge of the float
(<code>project_name</code> column)</p></li>
<li><p>name of principal investigator in charge of the float
(<code>pi_name</code> column)</p></li>
<li><p>float cycle number (<code>cycle_number</code> column; <em>cycle 0
is the launch cycle during which technical data or configuration
information is transmitted; cycle 1 is the first complete
cycle</em>)</p></li>
<li><p>descending (D) or ascending (A) profile (<code>direction</code>
column). <em>Profile measurements are taken on ascent, occasionally
during descent (rarely both).</em></p></li>
<li><p>code for the data centre in charge of the float data management
(<code>data_centre</code> column)</p></li>
<li><p>the type of float (<code>platform_type</code> column)</p></li>
<li><p>firmware version of the float (<code>firmware_version</code>
column)</p></li>
<li><p>instrument type from the WMO code table 1770
(<code>wmo_inst_type</code> column)</p></li>
<li><p>the date and time at which the measurement was taken, in UTC
(<code>date</code> column)</p></li>
<li><p>a quality control flag for the date and time value
(<code>date_qc</code> column)</p></li>
<li><p>the date and time of the profile location
(<code>date_location</code> column)</p></li>
<li><p>latitude in degrees N (<code>latitude</code> column)</p></li>
<li><p>longitude in degrees E (<code>longitude</code> column)</p></li>
<li><p>quality control flag on the position (<code>position_qc</code>
column)</p></li>
<li><p>name of the system in charge of positioning the float locations
(<code>positioning_system</code> column)</p></li>
<li><p>unique number of the mission to which this float belongs
(<code>config_mission_number</code> column,</p></li>
<li><p>a global quality control flag on the profile of the parameter
(<code>profile_parameter_qc</code> column; FillValue = ” “)</p></li>
</ul>
</div>
<div id="qc-flags" class="section level2">
<h2>QC flags</h2>
<p>QC flags for values (‘<code>parameter_adjusted_qc</code>’ columns)
are between 1 and 8, where:<br />
1 is ‘good’ data,<br />
2 is ‘probably good’ data,<br />
3 is ‘probably bad’ data,<br />
4 is ‘bad’ data,<br />
5 is ‘value changed’,<br />
8 is ‘estimated value’,<br />
9 is ‘missing value’ (data parameter will record FillValue)<br />
(6 and 7 are not used).</p>
<p>Profile QC flags (‘<code>profile_parameter_qc</code>’ columns) are QC
codes attributed to the entire profile, and indicate the number of depth
levels (in %) where the value is considered to be good data (QC flags of
1, 2, 5, and 8; QC flags of 9 or ” ” are not used in the
computation):<br />
‘A’ means 100% of profile levels contain good data,<br />
‘B’ means 75-&lt;100% of profile levels contain good data,<br />
‘C’ means 50-75% of profile levels contain good data,<br />
‘D’ means 25-50% of profile levels contain good data,<br />
‘E’ means &gt;0-25% of profile levels contain good data,<br />
‘F’ means 0% of profile levels contain good data.</p>
<div id="quality-control-tests" class="section level3">
<h3>Quality Control Tests</h3>
<p>There are two levels of Argo data quality control:</p>
<ul>
<li>The first level is the real-time system that performs a set of
agreed automatic checks</li>
<li>The second level is the delayed-mode quality control system.</li>
</ul>
<div id="real-time-qc-tests" class="section level4">
<h4>Real-time QC tests</h4>
<ol style="list-style-type: decimal">
<li><strong>Platform identification test</strong></li>
</ol>
<p>If a float WMO ID cannot be matched to the correct float platform
then none of the data will be distributed.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Impossible date test</strong></li>
</ol>
<p>This test requires that the Julian Day of the float be later than 1st
January 1997 and earlier than the current date of the check (in UTC
time). If the date of a profile fails this test, the date of the profile
should be flagged as bad data (‘4’) and none of the profile data is
distributed.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Impossible location test</strong></li>
</ol>
<p>This test requires that the observation latitude and longitude of a
float be sensible, with latitude in the range -90 to 90º, and longitude
in the range -180 to 180º.</p>
<p>If either latitude or longitude fails this test, the position is
flagged as bad data (‘4’) and none of the profile data is
distributed.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Position on land test</strong></li>
</ol>
<p>This test requires that the observation latitude and longitude be
located in an ocean. If a position cannot be located in an ocean, the
position is flagged as bad data (‘4’) and none of the profile data is
distributed.</p>
<ol start="5" style="list-style-type: decimal">
<li><strong>Impossible speed test</strong></li>
</ol>
<p>Drift speeds for floats can be generated given the positions and
times of the floats when they are at the sea surface and between
profiles. In all cases, we would not expect the drift speed to exceed 3
ms<sup>-1</sup>. If it does, it means either the positions or times are
bad data, or a float is mislabeled. Using the multiple positions and
times that are normally available for a float while at the sea surface,
it is often possible to isolate the one position or time that is an
error.</p>
<p>If an acceptable position and time can be used from the available
suite, then the data can be distributed. Otherwise, the position, the
time, or both, are flagged as bad data (‘4’) and the profile data is not
distributed.</p>
<ol start="6" style="list-style-type: decimal">
<li><strong>Global range test</strong></li>
</ol>
<p>This test applies a gross filter on the values of <code>TEMP</code>,
<code>PRES</code>, and <code>PSAL</code>. The ranges need to accommodate
all of the expected extremes in the ocean.</p>
<ul>
<li>Pressure cannot be less than -5 dbar. If <code>PRES</code> &lt; -5,
then <code>PRES_QC</code> = ‘4’, <code>TEMP_QC</code> = ‘4’, and
<code>PSAL_QC</code> = ‘4’.</li>
<li>Pressure in the range -5 to -2.4 dbar should be considered ‘probably
bad’ data. If -5 ≤ <code>PRES</code> ≤ -2.4, then <code>PRES_QC</code> =
‘3’, <code>TEMP_QC</code> = ‘3’, <code>PSAL_QC</code> = ‘3’.</li>
<li>Temperature should be in the range -2.5 to 40.0 ºC. Outside of this
range <code>TEMP_QC</code> = ‘4’.</li>
<li>Salinity should be in the range 2 to 41.0 PSU. Outside of this
range, <code>PSAL_QC</code> = ‘4’.</li>
<li><code>DOXY</code> should be in the range -5 to 600 µmol
kg<sup>-1</sup>. Outside of this range, <code>DOXY_QC = '4'</code>.</li>
<li><code>PH_IN_SITU_TOTAL</code> should be in the range 7.3 to 8.5.
Outside of this range, <code>PH_IN_SITU_TOTAL_QC = '4'</code>.</li>
</ul>
<ol start="7" style="list-style-type: decimal">
<li><strong>Regional range test</strong> (CTD data)</li>
</ol>
<p>This test applies to certain regions of the world where conditions
can be further qualified. In this case, specific ranges for observations
from the Mediterranean Sea and the Red Sea further restrict what can be
accepted as reasonable values.</p>
<p>If a value fails this test, it is flagged as bad data (‘4’) and
removed from the initial distribution. If temperature and salinity at
the same pressure level both fail this test, both values are flagged as
bad data (‘4’) and values for pressure, temperature, and salinity are
removed from the distribution.</p>
<ol start="8" style="list-style-type: decimal">
<li><strong>Pressure increasing test</strong> (CTD data)</li>
</ol>
<p>This test requires that the vertical profile has pressures that are
monotonically increasing (assuming the pressure levels are ordered from
smallest to largest).</p>
<p>If there is a region of constant pressure, all but the first of the
consecutive constant pressure levels is flagged as bad data (‘4’). If
there is a region where pressure reverses, all of the pressures in the
reversed part of the profile are flagged as bad data (‘4’). All
pressures flagged as bad data and associated temperatures and salinities
are removed.</p>
<ol start="9" style="list-style-type: decimal">
<li><strong>Spike test</strong></li>
</ol>
<p>The difference between sequential measurements, where one measurement
is significantly different from adjacent ones, is a spike in both size
and gradient. This test does not consider differences in pressure, but
assumes a sampling that adequately reproduces changes in temperature and
salinity with pressure.</p>
<p>Test value = | V2 - (V3 + V1)/2 | - | (V3 - V1)/2 |</p>
<p>where V2 is the measurement being tested, and V1 and V3 are the
values above and below.</p>
<p>Temperature: the V2 value is flagged when:</p>
<ul>
<li>the test value exceeds 6.0 ºC for pressures less than 500 dbar,
or</li>
<li>the test value exceeds 2.0 ºC for pressures equal to or greater than
500 dbar.</li>
</ul>
<p>Salinity: the V2 value is flagged when:</p>
<ul>
<li>the test value exceeds 0.9 PSU for pressures less than 500 dbar,
or</li>
<li>the test value exceeds 0.3 PSU for pressures equal to or greater
than 500 dbar.</li>
</ul>
<p>DOXY: the V2 value is flagged when:</p>
<ul>
<li>the test value exceeds 50 µmol kg<sup>-1</sup> for pressures less
than 500 dbar, or</li>
<li>the test value exceeds 25 µmol kg<sup>-1</sup> for pressures equal
to or greater than 500 dbar.</li>
</ul>
<p>For pH:</p>
<p>Test value 2 = | V2 - median(V0, V1, V2, V3, V4) |</p>
<p>where the test value represents the anomaly of the observed pH from
the median of the surrounding data. A pH data point is considered a
spike and flagged as bad (‘4’) if Test Value 2 &gt; 0.04pH</p>
<p>If the value V2 fails this test, it is flagged as bad data (‘4’) and
is removed. If temperature and salinity both fail this test, both values
are flagged as bad data (‘4’) and values for temperature, salinity and
pressure are removed.</p>
<ol start="10" style="list-style-type: decimal">
<li>Obsolete</li>
<li><strong>Gradient test</strong> (DOXY only)</li>
</ol>
<p>This test is failed when the difference between vertically adjacent
measurements is too steep. The test does not consider changes in depth,
but assumes a sampling that adequately reproduces changes in DOXY with
depth</p>
<p>Test value = | V2 - (V3 + V1)/2 |</p>
<p>where V2 is the value being tested as a spike, and V1 and V3 are the
values above and below.</p>
<p>For DOXY, V2 is flagged when:</p>
<ul>
<li><p>the test value exceeds 50 µmol kg<sup>-1</sup> for pressures less
than 500 dbar, or</p></li>
<li><p>the test value exceeds 25 µmol kg<sup>-1</sup> for pressures
equal to or greater than 500 dbar</p></li>
</ul>
<ol start="12" style="list-style-type: decimal">
<li><strong>Digit rollover test</strong> (CTD data)</li>
</ol>
<p>Only so many bits are allowed to store temperature and salinity
values in a profiling float. This range is not always large enough to
accommodate conditions which are encountered in the ocean. When the
range is exceeded, stored values rollover to the lower end of the range.
This rollover should be detected and compensated for when profiles are
constructed from the data stream of the float. This test is used to make
sure the rollover is properly detected.</p>
<ul>
<li>Temperature difference between adjacent pressures &gt; 10 ºC</li>
<li>Salinity difference between adjacent pressures &gt; 5 PSU</li>
</ul>
<p>If a value fails this test, it is flagged as bad data (‘4’) and
removed from the initial distribution. If temperature and salinity at
the same pressure level both fail this test, both values are flagged as
bad data (‘4’) and values for pressure, temperature, and salinity are
removed from the distribution.</p>
<ol start="13" style="list-style-type: decimal">
<li><strong>Stuck value test</strong></li>
</ol>
<p>This test looks for CTD and BGC measurements in the same profile
being identical.</p>
<p>If this occurs, all of the values affected parameter are flagged as
bad data (‘4’) and removed from the distribution. If both temperature
and salinity are affected, then all observed values from the profile are
flagged as bad data (‘4’).</p>
<ol start="14" style="list-style-type: decimal">
<li><strong>Density inversion test</strong> (CTD data)</li>
</ol>
<p>This test compares potential density between valid measurements in a
profile in both directions (i.e., from top to bottom, and from bottom to
top). Values of temperature and salinity at the same pressure level
P<sub>i</sub> are used to compute potential density ρ<sub>i</sub> ( or
σ<sub>i</sub> = ρ<sub>i</sub> - 1000) kg m<sup>-3</sup>, referenced to
the mid-point between Pi and the next valid pressure level. A threshold
of 0.03 kg m<sup>-3</sup> is allowed for small density inversions.</p>
<p>From top to bottom, if the potential density calculated at the
greater pressure P<sub>i+1</sub> is less than that calculated at the
lesser pressure P<sub>i</sub> by more than 0.03 kg m<sub>-3</sub>, both
the temperature and salinity values at pressure P<sub>i</sub> are
flagged as bad data (‘4’). From bottom to top, if the potential density
calculated at the lesser pressure P<sub>i-1</sub> is greater than that
calculated at the greater pressure P<sub>i</sub> by more than 0.03 kg
m<sub>-3</sub>, both the temperature and salinity values at pressure
P<sub>i</sub> are flagged as bad data (‘4’). Bad temperature and
salinity are removed from the distribution.</p>
<ol start="15" style="list-style-type: decimal">
<li><strong>Grey list test</strong></li>
</ol>
<p>This test is implemented as a mechanism for data assembly centers
(DACs) to flag, in real-time, sensors that are potentially not working
correctly. Each DAC manages a grey list and sends it to the GDACs. The
merged grey list from all DACs is available from the GDACs.</p>
<p>Naming convention: <code>xxx_greylist.csv</code> (where
<code>xxx</code> is the DAC name, e.g., <code>aoml_greylist.csv</code>,
<code>coriolis_greylist.csv</code>, etc).</p>
<p>Columns: <code>PLATFORM</code>, <code>PARAMETER</code>,
<code>START_DATE</code>, <code>END_DATE</code>, <code>QC</code>,
<code>COMMENT</code>, <code>DAC</code></p>
<p>The decision to insert a float parameter in the grey list comes from
the PI or the delayed-mode operator. A float parameter should be put in
the grey list when the sensor drift is too big to be adjusted in
real-time, or when the sensor is judged to be potentially not working
correctly.</p>
<p>The grey list concerns only real-time files. When an anomalous float
is dead and the offending parameter has been adjusted in delayed-mode,
it is removed from the grey list. When an anomalous float is active and
the offending parameter has been partially adjusted in delayed-mode, it
will remain on the grey list if real-time adjustment is not
adequate.</p>
<p>Grey-listed parameters are flagged as probably good (‘2’), probably
bad (‘3’) or bad (‘4’) data, as determined by the PI or the delayed-mode
operator.</p>
<ol start="16" style="list-style-type: decimal">
<li><strong>Gross salinity or temperature sensor drift test</strong>
(CTD)</li>
</ol>
<p>This test is implemented to detect a sudden and significant sensor
drift. It calculates the average temperature and salinity from the
deepest 100 dbar of a profile and the previous good profile. Only
measurements with good QC are used.</p>
<p>For salinity, if the difference between the two average values is
more than 0.5 PSU, then all the salinity values of the profile are
flagged as probably bad data (‘3’). For temperature, if the difference
between the two average values is more than 1 ºC, then all the
temperature values from the profile are flagged as probably bad data
(‘3’).</p>
<ol start="17" style="list-style-type: decimal">
<li><strong>Visual QC test</strong></li>
</ol>
<p>This is subjective visual inspection of float measurements by an
operator. This test is not mandatory before real-time data
distribution.</p>
<ol start="18" style="list-style-type: decimal">
<li><strong>Frozen profile test</strong> (CTD data)</li>
</ol>
<p>This test is used to detect a float that produces the same profile
(with very small deviations) over and over again. Typically the
differences between two profiles are of the order of 0.001 PSU for
salinity and of the order 0.01 ºC for temperature.</p>
<ol style="list-style-type: upper-alpha">
<li><p>Derive temperature and salinity profiles by averaging the
original profiles to get mean values for each profile in 50 dbar slabs
(T_prof, T_previous_prof, S_prof, S_previous_prof). This is necessary
because the floats do not sample at the same level in each
profile.</p></li>
<li><p>Obtain absolute values of the difference between the averaged
temperature and salinity profiles as follows:</p></li>
</ol>
<ul>
<li>deltaT = abs(T_prof - T_previous_prof)</li>
<li>deltaS = abs(S_prof - S_previous_prof)</li>
</ul>
<ol start="3" style="list-style-type: upper-alpha">
<li>Find the maximum, minimum, and mean of the absolute values of the
averaged differences between profiles for temperature and salinity:</li>
</ol>
<ul>
<li>mean(deltaT), max(deltaT), min(deltaT)</li>
<li>mean(deltaS), max(deltaS), min(deltaS)</li>
</ul>
<ol start="4" style="list-style-type: upper-alpha">
<li>To fail the test, require that:</li>
</ol>
<ul>
<li>max(deltaT) &lt; 0.3 ºC</li>
<li>min(deltaT) &lt; 0.001 ºC</li>
<li>mean(deltaT) &lt; 0.02 ºC</li>
<li>max(deltaS) &lt; 0.3 PSU</li>
<li>min(deltaS) &lt; 0.001 PSU</li>
<li>mean(deltaS) &lt; 0.004 PSU</li>
</ul>
<p>If a profile fails this test, all measurements from this profile are
flagged as bad data (‘4’). If a float fails this test over 5 consecutive
cycles, it is inserted in the grey list.</p>
<ol start="19" style="list-style-type: decimal">
<li><strong>Deepest pressure test</strong></li>
</ol>
<p>This test requires that a profile has pressures that are not greater
than <code>CONFIG_ProfilePressure_dbar</code> plus 10%. The value of
<code>CONFIG_ProfilePressure_dbar</code> is in the meta.nc file of the
float.</p>
<p>If there is a region of incorrect pressures, those pressures and
their corresponding temperature and salinity measurements are flagged as
bad data (‘4’). Pressures flagged as bad data and their associated
measurements should be removed from distribution.</p>
<ol start="25" style="list-style-type: decimal">
<li><strong>MEDian with a distance (MEDD) test</strong> (CTD)</li>
</ol>
<p>This test is a set of algorithms based on three main steps:</p>
<ul>
<li>First, the computation of a sliding median with some
customizations</li>
<li>Then, limits are computed that are at relative 2-dimension distance
d from the median</li>
<li>Finally, these limits are also computed for the density profile.
There is a spike if both the density profile measurement profile are out
of limits. If there is no conductivity sensor, then the spikes in
temperature are evaluated using a bigger d value.</li>
</ul>
<p>Temperature and salinity values that fail this test are flagged as
bad data (‘4’).</p>
<ol start="56" style="list-style-type: decimal">
<li><strong>pH-specific real-time QC test</strong> (PH_IN_SITU_TOTAL
only)</li>
</ol>
<p>Currently, there is no pH-specific QC test. If one is established, it
will be reported with the number ‘56’.</p>
<p>Real-time pH values which pass the real-time QC tests are assigned QC
flags of ‘3’. The Argo goals for research-quality data require that pH
values be adjusted to receive a quality flag of ‘1’.</p>
<ol start="57" style="list-style-type: decimal">
<li><strong>DOXY-specific real-time QC test</strong> (DOXY only)</li>
</ol>
<p>Real-time unadjusted <code>DOXY</code>values receive QC flags of ‘3’.
This is because the majority of oxygen sensors deployed on BGC Argo
profiling floats are Aanderaa optodes that suffer from pre-deployment
storage drift that can reduce accuracy by up to 20% or more. Because
this is a known bias that affects the majority of oxygen sensors within
the array, and because it can be corrected, <code>DOXY_QC</code> is set
to ‘3’.</p>
<ol start="59" style="list-style-type: decimal">
<li><strong>Nitrate-specific real-time QC test</strong> (NITRATE
only)</li>
</ol>
<p><em>Not yet available</em></p>
</div>
<div id="test-application-order-on-vertical-profiles"
class="section level4">
<h4>Test application order on vertical profiles</h4>
<p>The Argo real-time QC tests on CTD data (temperature, salinity,
pressure) are performed in the order described in the following
table.</p>
<p>A CTD measurement with a QC flag ‘4’ is ignored by other QC tests. A
measurement with QC flag ‘2’ or ‘3’ is tested by other QC tests.</p>
<p>A <code>DOXY</code> measurement with a QC flag ‘4’ or ‘3’ is ignored
by other QC tests.</p>
<p>Note that the Test Number is different from the Application Order.
The Test Number (n) is a number assigned permanently to each QC test. It
is used to fill <code>HISTORY_QCTEST</code> in the Argo profile files.
Therefore, each Test Number is uniquely associated to a QC test, and is
never replaced, changed, or duplicated.</p>
<p>Each real-time QC test has a unique Binary ID (2<sup>n</sup>) of the
unique Test Number (n) is used to record QC tests performed and failed
in the variable <code>HISTORY_QCTEST</code>.</p>
<p>The QC flag assigned by a test cannot override a higher value
assigned by a previous QC test.</p>
<p>e.g.: a QC flag ‘4’ (bad data) set by the Grey List Test cannot be
decreased to QC flag ‘3’ (bad data that are potentially correctable) set
by the Gross Salinity or Temperature Sensor Drift Test.</p>
<table>
<colgroup>
<col width="31%" />
<col width="13%" />
<col width="14%" />
<col width="40%" />
</colgroup>
<thead>
<tr class="header">
<th>Application Order for CTD parameters</th>
<th>Test Number (n)</th>
<th>Binary ID (2<sup>n</sup>)</th>
<th>Test Name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>1</td>
<td>2</td>
<td>Platform Identification Test</td>
</tr>
<tr class="even">
<td>2</td>
<td>2</td>
<td>4</td>
<td>Impossible Date Test</td>
</tr>
<tr class="odd">
<td>3</td>
<td>3</td>
<td>8</td>
<td>Impossible Location Test</td>
</tr>
<tr class="even">
<td>4</td>
<td>4</td>
<td>16</td>
<td>Position on Land Test</td>
</tr>
<tr class="odd">
<td>5</td>
<td>5</td>
<td>32</td>
<td>Impossible Speed Test</td>
</tr>
<tr class="even">
<td>6</td>
<td>15</td>
<td>32768</td>
<td>Grey List Test</td>
</tr>
<tr class="odd">
<td>7</td>
<td>19</td>
<td>524288</td>
<td>Deepest Pressure Test</td>
</tr>
<tr class="even">
<td>8</td>
<td>6</td>
<td>64</td>
<td>Global Range Test</td>
</tr>
<tr class="odd">
<td>9</td>
<td>7</td>
<td>128</td>
<td>Regional Range Test</td>
</tr>
<tr class="even">
<td>10</td>
<td>8</td>
<td>256</td>
<td>Pressure Increasing Test</td>
</tr>
<tr class="odd">
<td>11</td>
<td>9</td>
<td>512</td>
<td>Spike Test</td>
</tr>
<tr class="even">
<td>12</td>
<td>25</td>
<td>33554432</td>
<td>MEDD Test</td>
</tr>
<tr class="odd">
<td>13</td>
<td>12</td>
<td>4096</td>
<td>Digit Rollover Test</td>
</tr>
<tr class="even">
<td>14</td>
<td>13</td>
<td>8192</td>
<td>Stuck Value Test</td>
</tr>
<tr class="odd">
<td>15</td>
<td>14</td>
<td>16384</td>
<td>Density Inversion Test</td>
</tr>
<tr class="even">
<td>16</td>
<td>16</td>
<td>65536</td>
<td>Gross Salinity or Temperature Sensor Drift Test</td>
</tr>
<tr class="odd">
<td>17</td>
<td>18</td>
<td>261144</td>
<td>Frozen Profile Test</td>
</tr>
<tr class="even">
<td><em>18</em></td>
<td><em>17</em></td>
<td>131072</td>
<td><em>Visual QC Test</em></td>
</tr>
</tbody>
</table>
<p>The real-time tests for BGC parameters are performed in the order
described in the following table:</p>
<table>
<colgroup>
<col width="28%" />
<col width="12%" />
<col width="13%" />
<col width="45%" />
</colgroup>
<thead>
<tr class="header">
<th>Application order for BGC parameters</th>
<th>Test Number (n)</th>
<th>Binary ID (2<sup>n</sup>)</th>
<th>Test Name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>19</td>
<td>524288</td>
<td>Deepest Pressure Test</td>
</tr>
<tr class="even">
<td>2</td>
<td>1</td>
<td>2</td>
<td>Platform Identification Test</td>
</tr>
<tr class="odd">
<td>3</td>
<td>2</td>
<td>4</td>
<td>Impossible Date Test</td>
</tr>
<tr class="even">
<td>4</td>
<td>3</td>
<td>8</td>
<td>Impossible Location Test</td>
</tr>
<tr class="odd">
<td>5</td>
<td>4</td>
<td>16</td>
<td>Position on Land Test</td>
</tr>
<tr class="even">
<td>6</td>
<td>5</td>
<td>32</td>
<td>Impossible Speed Test</td>
</tr>
<tr class="odd">
<td>7</td>
<td>6</td>
<td>64</td>
<td>Global Range Test</td>
</tr>
<tr class="even">
<td>8</td>
<td>7</td>
<td>128</td>
<td>Regional Range Test</td>
</tr>
<tr class="odd">
<td>9</td>
<td>9</td>
<td>512</td>
<td>Spike Test</td>
</tr>
<tr class="even">
<td>10</td>
<td>11</td>
<td>2048</td>
<td>Gradient Test</td>
</tr>
<tr class="odd">
<td>11</td>
<td>12</td>
<td>4096</td>
<td>Digit Rollover Test</td>
</tr>
<tr class="even">
<td>12</td>
<td>13</td>
<td>8192</td>
<td>Stuck Value Test</td>
</tr>
<tr class="odd">
<td>13</td>
<td>15</td>
<td>32768</td>
<td>Grey List Test</td>
</tr>
<tr class="even">
<td><em>14</em></td>
<td><em>16</em></td>
<td><em>65536</em></td>
<td><em>Gross Temperature Sensor Drift Test (only for
TEMP_DOXY)</em></td>
</tr>
<tr class="odd">
<td>15</td>
<td>18</td>
<td>261144</td>
<td>Frozen Profile Test</td>
</tr>
<tr class="even">
<td>16</td>
<td></td>
<td></td>
<td>BGC parameter-specific tests</td>
</tr>
<tr class="odd">
<td><em>17</em></td>
<td><em>17</em></td>
<td><em>131072</em></td>
<td><em>Visual QC Test</em></td>
</tr>
</tbody>
</table>
</div>
<div id="delayed-mode-quality-control" class="section level4">
<h4>Delayed-Mode Quality Control</h4>
<p>The QC flags determined in delayed-mode replace those assigned in
real-time because some bad data cannot be detected by the real-time
tests, and some good data can be identified wrongly as bad by the
real-time tests.</p>
<p>For vertical profile data, delayed-mode operators examine them for
pointwise errors (such as spikes and jumps) and flag them appropriately.
If an error is identified, both <code>PARAM_QC</code> and
<code>PARAM_ADJUSTED_QC</code> record ‘4’. Conversely, if good data have
wrongly been identified as bad by the real-time tests, then
<code>PARAM_QC</code> and <code>PARAM_ADJUSTED_QC</code> record ‘1’.</p>
<p>In SD-files, the variables <code>PROFILE_PARAMETER_QC</code>,
<code>PARAMETER_ADJUSTED</code>, <code>PARAMETER_ADJUSTED_QC</code>, and
<code>PARAMETER_ADJUSTED_ERROR</code> are compulsory. If no adjustment
in delayed-mode is necessary and if the flag is deemed assigned
correctly, then <code>PARAM_ADJUSTED = PARAMETER</code>,
<code>PARAM_ADJUSTED_QC = PARAM_QC</code>, and
<code>PARAM_ADJUSTED_ERROR</code> is provided by the PI.</p>
<p>If no delayed-mode adjustment was performed, then
<code>PARAM_ADJUSTED = 99999.f</code>,
<code>PARAM_ADJUSTED_QC = " "</code>,
<code>PARAM_ADJUSTED_ERROR = 99999.f</code> and
<code>PROFILE_PARAMETER_QC = " "</code>.</p>
<p>If values are deemed unadjustable in delayed-mode, then
<code>PARAM_ADJUSTED_QC = '4'</code>, and
<code>PARAM_ADJUSTED = 99999.f</code> and
<code>PARAM_ADJUSTED_ERROR = 99999.f</code>.</p>
<p>The variable <code>PROFILE_PARAMETER_QC</code> is recomputed when
<code>PARAMETER_ADJUSTED_QC</code> becomes available.</p>
<p><strong>Dates</strong></p>
<p>Delayed-mode operators check that the dates in the profile are in
chronological order. Erroneous or missing dates are replaced with
another telemetered value if available, or replaced with interpolated
values and marked <code>DATE_QC = '8'</code>.</p>
<p><strong>Location</strong></p>
<p>Profile positions <code>LONGITUDE</code>, <code>LATITUDE</code> are
checked for outliers. Erroneous or missing dates are replaced with
another telemetered value if available, or replaced with interpolated
values and marked <code>POSITION_QC = '8'</code>.</p>
<p><strong>Pressure, Temperature, Salinity</strong></p>
<p>Delayed-mode quality control of <code>PRES</code> and
<code>TEMP</code> is done by subjective assessment of vertical profile
plots of <code>TEMP</code> vs <code>PRES</code> and <code>PSAL</code> vs
<code>PRES</code> and <code>PRES</code> vs <code>TEMP</code> and
<code>PSAL</code> vs <code>TEMP</code>. This assessment is done in
relation to measurements from the same float, as well as in relation to
nearby floats and historical data. This assessment aims to identify: (a)
erroneous data points that cannot be detected by real-time QC tests, and
(b) vertical profiles that have the wrong shape.</p>
<p>Bad <code>PRES</code> data points identified by visual inspection
from delayed-mode analysts are recorded with
<code>PRES_ADJUSTED_QC = '4'</code> and <code>PRES_QC = '4'</code>. For
these bad data points, <code>TEMP_ADJUSTED_QC</code>,
<code>TEMP_QC</code>, <code>PSAL_ADJUSTED_QC</code>, and
<code>PSAL_QC</code> are also set to ‘4’.</p>
<p>Bad <code>TEMP</code> data points are recorded with
<code>TEMP_ADJUSTED_QC = '4'</code> and <code>TEMP_QC = '4'</code>.
<code>TEMP_ADJUSTED</code>, <code>TEMP_ADJUSTED_QC</code>,
<code>TEMP_ADJUSTED_ERROR</code> are filled even when the data is good
and no adjustment is needed. In these cases,
<code>TEMP_ADJUSTED_ERROR</code> can be the manufacturer’s quoted
accuracy at deployment, which is 0.002 ºC.</p>
<p>Delayed-mode quality control of PSAL is done by checking for sensor
offsets and drifts, as well as other instrument errors. Float salinity
values that are considered adjustable in delayed-mode are compiled into
time-series. Sufficiently long time-series are compared with statistical
recommendations and uncertainties to check for sensor drift and
offset.</p>
<p>After assessing all available information, the PI records
<code>PSAL_ADJUSTED</code>, <code>PSAL_ADJUSTED_QC</code>, and
<code>PSAL_ADJUSTED_ERROR</code>. Salinity data considered bad and
unadjustable in delayed-mode are given
<code>PSAL_ADJUSTED_QC = '4'</code>, and <code>PSAL_ADJUSTED</code> and
<code>PSAL_ADJUSTED_ERROR</code> are set to FillValue.</p>
<p><strong>Oxygen</strong></p>
<p>Raw <code>DOXY</code> values are adjusted in delayed-mode to account
for sensor drift and bias. The errors associated with this calibration
are recorded in <code>DOXY_ADJUSTED_ERROR</code> in µmol
kg<sup>-1</sup>.</p>
<p>When <code>DOXY</code> for the whole profile is bad and cannot be
adjusted, then <code>DOXY_ADJUSTED = 99999.f</code>,
<code>DOXY_ADJUSTED_ERROR = 99999.f</code>, and
<code>DOXY_ADJUSTED_QC = '4'</code>. The calibration information is
recorded as <code>SCIENTIFIC_CALIB_EQUATION = 'none'</code>,
<code>SCIENTIFIC_CALIB_EQUATION = 'none'</code>, and
<code>SCIENTIFIC_CALIB_COMMENT = 'Bad data; not adjustable'</code>.</p>
<p><strong>pH</strong></p>
<p>The pH adjustment process depends on having an accurate model for pH
below 1000 m, where temporal and spatial variability is minimal. pH
values are adjusted using Multiple Linear Regression (MLR) methods,
Linearly Interpolated Regression equations, and a neural network
prediction system known as CANYON. The expected error in float pH
measurements is derived from the uncertainty in the reference data as
well as sensor uncertainties.</p>
<p>The empirical algorithms used in the adjustment process for pH
are:</p>
<p>the MLR method of Williams et al. (2016)</p>
<p>the LIR method of Carter et al. (2018)</p>
<p>the CANYON method of Sauzede et al. (2017)</p>
<p>The method used for adjustment is recorded in
<code>SCIENTIFIC_CALIB_EQUATION</code>,
<code>SCIENTIFIC_CALIB_COEFFICIENT</code>, and
<code>SCIENTIFIC_CALIB_COMMENT</code></p>
<p><strong>Quality control manuals</strong></p>
<p><em>CTD data quality control: <a
href="https://archimer.ifremer.fr/doc/00228/33951/32470.pdf"
class="uri">https://archimer.ifremer.fr/doc/00228/33951/32470.pdf</a>
(<a href="http://dx.doi.org/10.13155/33951"
class="uri">http://dx.doi.org/10.13155/33951</a></em><strong>)</strong></p>
<p><em>Oxygen data quality control: <a
href="https://archimer.ifremer.fr/doc/00354/46542/82301.pdf"
class="uri">https://archimer.ifremer.fr/doc/00354/46542/82301.pdf</a>
(<a href="http://dx.doi.org/10.13155/46542"
class="uri">http://dx.doi.org/10.13155/46542</a></em>)</p>
<p><em>pH data quality control: <a
href="https://archimer.ifremer.fr/doc/00460/57195/61336.pdf"
class="uri">https://archimer.ifremer.fr/doc/00460/57195/61336.pdf</a>
(<a href="https://doi.org/10.13155/57195"
class="uri">https://doi.org/10.13155/57195</a>)</em></p>
<p><em>BGC data quality control: <a
href="https://archimer.ifremer.fr/doc/00298/40879/42267.pdf"
class="uri">https://archimer.ifremer.fr/doc/00298/40879/42267.pdf</a>
(<a href="http://dx.doi.org/10.13155/40879"
class="uri">http://dx.doi.org/10.13155/40879</a>)</em></p>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.2.2 (2022-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: openSUSE Leap 15.4

Matrix products: default
BLAS:   /usr/local/R-4.2.2/lib64/R/lib/libRblas.so
LAPACK: /usr/local/R-4.2.2/lib64/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] ggOceanMaps_1.3.4 ggspatial_1.1.7   oce_1.7-10        gsw_1.1-1        
 [5] sf_1.0-9          lubridate_1.9.0   timechange_0.1.1  argodata_0.1.0   
 [9] forcats_0.5.2     stringr_1.4.1     dplyr_1.0.10      purrr_0.3.5      
[13] readr_2.1.3       tidyr_1.2.1       tibble_3.1.8      ggplot2_3.4.0    
[17] tidyverse_1.3.2  

loaded via a namespace (and not attached):
 [1] fs_1.5.2            bit64_4.0.5         progress_1.2.2     
 [4] httr_1.4.4          rprojroot_2.0.3     tools_4.2.2        
 [7] backports_1.4.1     bslib_0.4.1         utf8_1.2.2         
[10] R6_2.5.1            KernSmooth_2.23-20  rgeos_0.5-9        
[13] DBI_1.1.3           colorspace_2.0-3    raster_3.6-11      
[16] withr_2.5.0         sp_1.5-1            prettyunits_1.1.1  
[19] tidyselect_1.2.0    bit_4.0.5           compiler_4.2.2     
[22] git2r_0.30.1        cli_3.4.1           rvest_1.0.3        
[25] RNetCDF_2.6-1       xml2_1.3.3          labeling_0.4.2     
[28] sass_0.4.4          scales_1.2.1        classInt_0.4-8     
[31] proxy_0.4-27        digest_0.6.30       rmarkdown_2.18     
[34] pkgconfig_2.0.3     htmltools_0.5.3     highr_0.9          
[37] dbplyr_2.2.1        fastmap_1.1.0       rlang_1.1.1        
[40] readxl_1.4.1        rstudioapi_0.14     farver_2.1.1       
[43] jquerylib_0.1.4     generics_0.1.3      jsonlite_1.8.3     
[46] vroom_1.6.0         googlesheets4_1.0.1 magrittr_2.0.3     
[49] Rcpp_1.0.10         munsell_0.5.0       fansi_1.0.3        
[52] lifecycle_1.0.3     terra_1.7-39        stringi_1.7.8      
[55] whisker_0.4         yaml_2.3.6          grid_4.2.2         
[58] parallel_4.2.2      promises_1.2.0.1    crayon_1.5.2       
[61] lattice_0.20-45     haven_2.5.1         hms_1.1.2          
[64] knitr_1.41          pillar_1.8.1        codetools_0.2-18   
[67] reprex_2.0.2        glue_1.6.2          evaluate_0.18      
[70] modelr_0.1.10       vctrs_0.5.1         tzdb_0.3.0         
[73] httpuv_1.6.6        cellranger_1.1.0    gtable_0.3.1       
[76] assertthat_0.2.1    cachem_1.0.6        xfun_0.35          
[79] broom_1.0.1         e1071_1.7-12        later_1.3.0        
[82] class_7.3-20        googledrive_2.0.0   gargle_1.2.1       
[85] workflowr_1.7.0     units_0.8-0         ellipsis_0.3.2     </code></pre>
</div>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
