---
title: "Load Core-Argo Data"
author: "David Stappard, Pasqualina Vonlanthen & Jens Daniel MÃ¼ller"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: workflowr::wflow_html
editor_options:
chunk_output_type: console
---


```{r set_options_global, include=FALSE}

knitr::opts_chunk$set(warning = FALSE, message = FALSE)

```

# Task
Load core-Argo temperature data for comparison with BGC-Argo temperature data  


```{r loading_libraries, include=FALSE}

library(tidyverse)
# remotes::install_github('ArgoCanada/argodata')
library(argodata)
library(ggplot2)
library(lubridate)
# install.packages('sf')
# install.packages("oce")
library(sf)
library(oce)
library(gsw)
# install.packages('ggspatial')
# devtools::install_github("MikkoVihtakari/ggOceanMapsData")
# devtools::install_github("MikkoVihtakari/ggOceanMaps")
# library(ggspatial)
# library(ggOceanMaps)
```


```{r set_updata_root_directory, include=FALSE}

path_argo <- '/nfs/kryo/work/datasets/ungridded/3d/ocean/floats/bgc_argo'
path_argo_core <- '/nfs/kryo/work/datasets/ungridded/3d/ocean/floats/core_argo_r_argodata'
path_argo_core_preprocessed <- paste0(path_argo_core, "/preprocessed_core_data")

```

## Set load options

Determine if files are refreshed from dac or cache directory is used. 
Are metadata, temperature and salinity year files renewed?
Are the consolidated all year files created from the individual year files?

```{r set_load_options}

# opt_refresh_cache
#   0 = do not refresh cache.
#   1 = refresh cache. (any none zero value will force a refresh)
opt_refresh_cache = 0

# opt_refresh_years_temp, opt_refresh_years_psal, opt_refresh_years_metadata
#   0 = do not refresh the yearly files. (any value <> 1 will omit annual refresh)
#   1 = refresh yearly files for given parameter.
#   year to be refreshed are set by opt_min_year and opt_max_year
opt_refresh_years_temp = 1
opt_refresh_years_psal = 1
opt_refresh_years_metadata = 1
opt_min_year = 2013
opt_max_year = 2023

# opt_consolidate_temp, opt_consolidate_psal, opt_consolidate_metadata
# Yearly files must have already been created!
#   0 = do not build consolidated file from previously written yearly files. (any value <> 1 will omit consolidation)
#   1 = build consolidated file from previously written yearly files for given parameter.
#   year to be included in the consolidation are set by opt_min_year and opt_max_year
opt_consolidate_temp = 1
opt_consolidate_psal = 1
opt_consolidate_metadata = 1

# opt_A_AB_files
# consolidated temp files must have already been created!
#   0 = do not build temp_A and temp_AB file from previously written consolidated files. (any value <> 1 will omit A and AB files)
#   1 = build temp_A and temp_AB file from previously written consolidated files.
opt_A_AB_files = 1

# opt_review_mode
# if set (1) the processing will take place in a sub-directory opt_review_dir and only process 10 days of profiles per year to reduce size
# of output and processing time
opt_review_mode = 1
opt_review_dir = "/review_mode"

if (opt_review_mode == 1) {
  path_argo_core_preprocessed <- paste0(path_argo_core, "/preprocessed_core_data", opt_review_dir)
}

```

## Set cache directory 

Directory where the core-Argo profile files are stored. Either use the cached files or force a refresh from dac (long process)

```{r set_core_cache_directory}

# set cache directory
argo_set_cache_dir(cache_dir = path_argo_core)

# check cache directory
argo_cache_dir()

# check argo mirror
argo_mirror()

# age argument: age of the cached files to update in hours (Inf means always use the cached file, and -Inf means always download from the server) 
# ex: max_global_cache_age = 5 updates files that have been in the cache for more than 5 hours, max_global_cache_age = 0.5 updates files that have been in the cache for more than 30 minutes, etc.
if (opt_refresh_cache == 0){
  argo_update_global(max_global_cache_age = Inf)  
  argo_update_data(max_data_cache_age = Inf)
} else {
  argo_update_global(max_global_cache_age = -Inf)  
  argo_update_data(max_data_cache_age = -Inf)
}
```


## Load core data one year at a time - temperature, salinity and metadata data

Builds yearly files for temperature, salinity and metadata that can be consolidated in the next code chunk (consolidate_into_allyears)

```{r load_core_by_year}
#------------------------------------------------------------------------------
# Important - file are loaded for the given year processed and the files written to disk.
#------------------------------------------------------------------------------

for (target_year in opt_min_year:opt_max_year) {
  # for manual testing of the loop
  # target_year <- 2014


  # if updating any year files it will be based on the initial index file core_index
  if (opt_refresh_years_temp == 1 | opt_refresh_years_psal == 1 | opt_refresh_years_metadata == 1)
  {
    # if working in reiew mode only consider first 10 days of the year
    if (opt_review_mode == 1) {
      core_index <- argo_global_prof() %>% 
        argo_filter_data_mode(data_mode = 'delayed') %>% 
        argo_filter_date(date_min = paste0(target_year, "-01-01"),
                         date_max = paste0(target_year, "-01-10"))
    } else {
      core_index <- argo_global_prof() %>% 
        argo_filter_data_mode(data_mode = 'delayed') %>% 
        argo_filter_date(date_min = paste0(target_year, "-01-01"),
                         date_max = paste0(target_year, "-12-31"))
    }
  }

  # if temp or psal are being updated get the profile data
  if (opt_refresh_years_temp == 1 | opt_refresh_years_psal == 1)
  {
    # read in the profiles (takes a while)
    core_data_yr <- argo_prof_levels(
      path = core_index,
      vars =
        c(
          'PRES_ADJUSTED',
          'PRES_ADJUSTED_QC',
          'PSAL_ADJUSTED',
          'PSAL_ADJUSTED_QC',
          'TEMP_ADJUSTED',
          'TEMP_ADJUSTED_QC'),
      quiet = TRUE
    )
    
    # We only want the synthesized profiles i.e. n_prof == 1
    # Can you provide here a brief reminder what "synthesized" means?
    # Is this equivalent to the argument data_mode = 'delayed' provided to argo_filter_data_mode()
    # Do you think we should specify n_prof == 1 as a load option?
    core_data_yr <- core_data_yr %>%
    filter(n_prof == 1)

  } 

  # if updating metadata get the file based on core_index
  if (opt_refresh_years_metadata == 1)
  {
    # read associated metadata
    core_metadata_yr <- argo_prof_prof(path = core_index)
    
    # We only want the synthesized profiles i.e. n_prof == 1
    core_metadata_yr <- core_metadata_yr %>%
    filter(n_prof == 1)

  }
  
  
  # remove columns that are not needed in merged temperature and salinity files
  core_index <- core_index %>%
    select(file,
           date,
           latitude,
           longitude)
  
  # resolve lat and lon
  core_index <- core_index %>%
    rename(lon = longitude,
           lat = latitude) %>%
    mutate(lon = if_else(lon < 20, lon + 360, lon)) %>%
    mutate(
      lat = cut(lat, seq(-90, 90, 1), seq(-89.5, 89.5, 1)),
      lat = as.numeric(as.character(lat)),
      lon = cut(lon, seq(20, 380, 1), seq(20.5, 379.5, 1)),
      lon = as.numeric(as.character(lon))
    )
  
  # join to index to incorporate date, lat and lon
  core_data_yr <- left_join(core_data_yr, core_index)
  
  # derive depth using TEOS=10
  core_data_yr <- core_data_yr %>%
    mutate(depth = gsw_z_from_p(pres_adjusted, latitude =  lat) * -1.0,
           .before = pres_adjusted)
  
  core_data_yr <-
    core_data_yr %>%
    select(-c(n_levels, n_prof, pres_adjusted))

  # ------------------------------------------------------------------------------
  # Process temperature file
  # ------------------------------------------------------------------------------
  if (opt_refresh_years_temp == 1)
  {    
    # Base temperature data where qc flag = good
    # Could this cause incomplete profiles to be maintained?
    core_data_temp_yr <- core_data_yr %>%
      filter(
        pres_adjusted_qc %in% c(1, 8) &
        temp_adjusted_qc %in% c(1, 8)
      ) %>%
      select(
        -contains(c("_qc", "psal"))
      )
    
    # write this years file
    core_data_temp_yr %>% 
      write_rds(file = paste0(path_argo_core_preprocessed, "/", target_year, "_core_data_temp.rds"))

  }
  
  # ------------------------------------------------------------------------------
  # Process salinity file
  # ------------------------------------------------------------------------------
  if (opt_refresh_years_psal == 1)
  {    
    # Base salinity data where qc flag = good
    core_data_psal_yr <- core_data_yr %>%
      filter(
        pres_adjusted_qc %in% c(1, 8) &
        psal_adjusted_qc %in% c(1, 8)
      ) %>%
      select(
        -contains(c("_qc", "psal"))
      )

    # write this years file
    core_data_psal_yr %>% 
      write_rds(file = paste0(path_argo_core_preprocessed, "/", target_year, "_core_data_psal.rds"))

  }


  # ------------------------------------------------------------------------------
  # Process metadata file
  # ------------------------------------------------------------------------------
  if (opt_refresh_years_metadata == 1)
  {
    # resolve lat and lon so that it is hamonised with data files
    core_metadata_yr <- core_metadata_yr %>%
      rename(lon = longitude,
             lat = latitude) %>%
      mutate(lon = if_else(lon < 20, lon + 360, lon)) %>%
      mutate( 
        lat = cut(lat, seq(-90, 90, 1), seq(-89.5, 89.5, 1)),
        lat = as.numeric(as.character(lat)),
        lon = cut(lon, seq(20, 380, 1), seq(20.5, 379.5, 1)),
        lon = as.numeric(as.character(lon))
      )
  
    # Select just the columns we are interested in
    core_metadata_yr <- core_metadata_yr %>%
      select (
        file,
        date,
        lat,
        lon,
        platform_number, 
        cycle_number,
        position_qc,
        profile_pres_qc,
        profile_temp_qc,
        profile_psal_qc
      )

    # write this years file
    core_metadata_yr %>% 
      write_rds(file = paste0(path_argo_core_preprocessed, "/", target_year, "_core_metadata.rds"))

  }
  
}

```

## Build consolidated all year file from series of yearly files - temperature, salinity and metadata data

This process create three files in the path_argo_core_preprocessed directory that will be used for further analysis

core_data_temp.rds
------------------
Contains approximately 500 measuring points per profile and only contains those points that are marked as good. Fields listed below
    file - the source file
    date - date of profile
    lat - aligned to closest 0.5Â° lat
    lon - aligned to closest 0.5Â° lon
    depth - calculated from pres_adjusted and latitude
    pres_adjusted - recorded and adjusted (after qc proccess) pressure
    temp_adjusted - recorded and adjusted (after qc proccess) temperature

core_data_psal.rds
------------------
Contains approximately 500 measuring points per profile and only contains those points that are marked as good. Fields listed below
    file - the source file
    date - date of profile
    lat - aligned to closest 0.5Â° lat
    lon - aligned to closest 0.5Â° lon
    depth - calculated from pres_adjusted and latitude
    pres_adjusted - recorded and adjusted (after qc proccess) pressure
    psal_adjusted - recorded and adjusted (after qc proccess) salinity

core_metadata.rds
-----------------
Contains 1 row per profile. Fields listed below
    file - the source file
    date - date of profile
    lat - aligned to closest 0.5Â° lat
    lon - aligned to closest 0.5Â° lon
    platform_number - identifier of float
    cycle_number - the profile number for the given float
    position_qc - qc flag associated with the positioning of the float profile
    profile_pres_qc - qc flag associated with the pressure readings of the profile (A-F)
    profile_temp_qc - qc flag associated with the temperature readings of the profile (A-F)
    profile_psal_qc - qc flag associated with the salinity readings of the profile (A-F)


```{r consolidate_into_allyears}

# ------------------------------------------------------------------------------
# Process temperature file
# ------------------------------------------------------------------------------
if (opt_consolidate_temp == 1){
  consolidated_created = 0
  
  for (target_year in opt_min_year:opt_max_year) {

    # read the yearly file based on target_year
    core_data_temp_yr <-
    read_rds(file = paste0(path_argo_core_preprocessed, "/", target_year, "_core_data_temp.rds"))

    # Combine into a consolidated all years file
    if (consolidated_created == 0) {
      core_data_temp <- core_data_temp_yr
      consolidated_created = 1
    } else {
      core_data_temp <- rbind(core_data_temp, core_data_temp_yr)
    }
  }
  
  # write consolidated files  
  core_data_temp %>% 
    write_rds(file = paste0(path_argo_core_preprocessed, "/core_data_temp.rds"))

  # remove files to free space
  rm(core_data_temp)
  rm(core_data_temp_yr)
  gc()
  
}

# ------------------------------------------------------------------------------
# Process salinity file
# ------------------------------------------------------------------------------
if (opt_consolidate_psal == 1){
  consolidated_created = 0
  
  for (target_year in opt_min_year:opt_max_year) {

    # read the yearly file based on target_year
    core_data_psal_yr <-
    read_rds(file = paste0(path_argo_core_preprocessed, "/", target_year, "_core_data_psal.rds"))

    # Combine into a consolidated all years file
    if (consolidated_created == 0) {
      core_data_psal <- core_data_psal_yr
      consolidated_created = 1
    } else {
      core_data_psal <- rbind(core_data_psal, core_data_psal_yr)
    }
  }
  
  # write consolidated files  
  core_data_psal %>% 
    write_rds(file = paste0(path_argo_core_preprocessed, "/core_data_psal.rds"))

  # remove files to free space
  rm(core_data_psal)
  rm(core_data_psal_yr)
  gc()
  
}

# ------------------------------------------------------------------------------
# Process metadata file
# ------------------------------------------------------------------------------
if (opt_consolidate_metadata == 1){
  consolidated_created = 0
  
  for (target_year in opt_min_year:opt_max_year) {

    # read the yearly file based on target_year
    core_metadata_yr <-
    read_rds(file = paste0(path_argo_core_preprocessed, "/", target_year, "_core_metadata.rds"))

    # Combine into a consolidated all years file
    if (consolidated_created == 0) {
      core_metadata <- core_metadata_yr
      consolidated_created = 1
    } else {
      core_metadata <- rbind(core_metadata, core_metadata_yr)
    }
  }
  
  # write consolidated files  
  core_metadata %>% 
    write_rds(file = paste0(path_argo_core_preprocessed, "/core_metadata.rds"))

  # remove files to free space
  rm(core_metadata)
  rm(core_metadata_yr)
  gc()
  
}


```

## A and AB flag focused temperature files

This process create two additional files in the path_argo_core_preprocessed directory that will be used for further analysis

core_temp_flag_A.rds
--------------------
only ontains profile where profile_pres_qc and profile_temp_qc both equal A (100%). Fields listed below
    lat - aligned to closest 0.5Â° lat
    lon - aligned to closest 0.5Â° lon
    date - date of profile
    depth - depth of observation
    temp_adjusted - recorded and adjusted (after qc proccess) temperature
    platform_number - identifier of float
    cycle_number - the profile number for the given float

core_temp_flag_AB.rds
--------------------
only ontains profile where profile_pres_qc and profile_temp_qc both either A (100%) or B (> 75%). Fields listed below
    lat - aligned to closest 0.5Â° lat
    lon - aligned to closest 0.5Â° lon
    date - date of profile
    depth - depth of observation
    temp_adjusted - recorded and adjusted (after qc proccess) temperature
    platform_number - identifier of float
    cycle_number - the profile number for the given float


```{r temp_A_AB_files}

if (opt_A_AB_files == 1){

  # Read temp and meta_data
  core_data_temp <-
  read_rds(file = paste0(path_argo_core_preprocessed, "/core_data_temp.rds"))
  core_metadata <-
  read_rds(file = paste0(path_argo_core_preprocessed, "/core_metadata.rds"))

  # Join temp and meta_data to form merge
  core_merge <- left_join(x = core_data_temp, 
                          y = core_metadata %>% 
                            select(file,
                                   platform_number,
                                   cycle_number,
                                   contains("_qc")))
  rm(core_data_temp)
  rm(core_metadata)
  gc()

  # Select just A profiles into core_temp_flag_A
  core_temp_flag_A <- core_merge %>%
    filter(profile_temp_qc == 'A' & profile_pres_qc == 'A') %>%
    select(-c(file, contains("_qc")))


  # write core_temp_flag_A
  core_temp_flag_A %>%
    write_rds(file = paste0(path_argo_core_preprocessed, "/core_temp_flag_A.rds"))
  rm(core_temp_flag_A)
  gc()

  # Select just AB profiles into core_temp_flag_A
  core_temp_flag_AB <- core_merge %>%
    filter((profile_temp_qc == 'A' | profile_temp_qc == 'B') & (profile_pres_qc == 'A' | profile_pres_qc == 'B')) %>%
    select(-c(file, contains("_qc")))

  # write core_temp_flag_AB
  core_temp_flag_AB %>%
    write_rds(file = paste0(path_argo_core_preprocessed, "/core_temp_flag_AB.rds"))
  rm(list = ls(pattern = 'core_'))
  gc()
  
}
  
```
