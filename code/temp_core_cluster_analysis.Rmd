---
title: "Temperature core cluster analysis"
author: "David Stappard & Jens Daniel Müller"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

```{r set_options_global, include=FALSE}

knitr::opts_chunk$set(warning = FALSE, message = FALSE)

```

# Tasks

Load existing files from anomoly analysis and carry out cluster analysis

```{r loading_libraries, include=FALSE}

library(tidyverse)
library(argodata)
library(lubridate)
library(gridExtra)
library(gsw)

```

## Set directories

location of pre-prepared data

```{r set_updata_root_directory, include=FALSE}

path_argo <- '/nfs/kryo/work/datasets/ungridded/3d/ocean/floats/bgc_argo'
path_argo_preprocessed <- paste0(path_argo, "/preprocessed_bgc_data")

path_core_argo <- '/nfs/kryo/work/datasets/ungridded/3d/ocean/floats/core_argo_r_argodata'
path_core_preprocessed <- paste0(path_core_argo, "/preprocessed_core_data")

path_emlr_utilities <- "/nfs/kryo/work/jenmueller/emlr_cant/utilities/files/"

```

## Set options

Define options that are used to determine what analysis is done

```{r set_options}

# Options

# opt_analysis_type
# opt_analysis_type = 1 do analysis to determine number of clusters to use
# opt_analysis_type = 2 do cluster analysis and further analysis on the identified clusters clusters
opt_analysis_type <- 2

# opt_num_clusters
# How many clusters are used in teh cluster analysis
opt_num_clusters <- 7

# opt_measure_label, opt_xlim and opt_xbreaks are associated formatting
opt_measure_label <- "temperature anomaly (°C)"
opt_xlim <- c(-4, 4)
opt_xbreaks <- c(-4, -2, 0, 2, 4)

# options relating to cluster analysis
opt_n_start <- 15
opt_max_iterations <- 500


```


```{r set_global_theme, include=TRUE}

theme_set(theme_bw())

map <-
  read_rds(paste(path_emlr_utilities,
                 "map_landmask_WOA18.rds",
                 sep = ""))

```

## Cluster analysis

### Preperation

Prepare data for cluster analysis

```{r cluster_analysis_prep}

temp_anomaly_va <- read_rds(file = paste0(path_core_preprocessed, "/temp_anomaly_va.rds"))


# select just 1500m profiles
temp_anomaly_va <- temp_anomaly_va %>% 
  filter(profile_range == 3)

# Simplified table ready to pivot
temp_anomaly_va_id <- temp_anomaly_va %>% 
  select(
    file_id,
    depth,
    anomaly)

# Check duplicate values and remove those profiles
check_duplicates <- temp_anomaly_va_id %>%
  group_by(file_id, depth) %>%
  summarise(count_measures = n()) %>%
  filter(count_measures > 1) %>%
  ungroup()

check_duplicates <- check_duplicates %>%
                    select (file_id, count_measures)

temp_anomaly_va_id2 <- full_join(temp_anomaly_va_id, check_duplicates)

temp_anomaly_va_id <- temp_anomaly_va_id2 %>% 
                            filter(is.na(count_measures)) %>%
                            select(file_id, depth, anomaly)
rm(temp_anomaly_va_id2)

                            
# wide table with each depth becoming a column
temp_anomaly_va_wide <- temp_anomaly_va_id %>%
  pivot_wider(names_from = depth, values_from = anomaly)

# Drop any rows with missing values N/A caused by gaps in climatology data
temp_anomaly_va_wide <- drop_na(temp_anomaly_va_wide)
profile_id <- temp_anomaly_va_wide %>% select(file_id)

# Table for cluster analysis
x <- temp_anomaly_va_wide %>%
        select(-c(file_id))
```

### Number of clusters

```{r cluster_analysis_determine_k}

if (opt_analysis_type == 1) {
  
  # kmeansAIC = function(fit){
  # 
  #   m = ncol(fit$centers)
  #   n = length(fit$cluster)
  #   k = nrow(fit$centers)
  #   D = fit$tot.withinss
  #   return(data.frame(AIC = D + 2*m*k,
  #                     BIC = D + log(n)*m*k))
  # }
  
  # cluster analysis - What k
  n_clusters <- 14
  
  wss <- numeric(n_clusters)
  aic <- numeric(n_clusters)
  bic <- numeric(n_clusters)
  
  for (i in 1:n_clusters) {
    
    # Fit the model: km.out
    print(paste0('Preparing to carry out test cluster analysis with ', i , ' clusters'))
    set.seed(1)
    (km_out <- kmeans(x, i, iter.max=opt_max_iterations, nstart=opt_n_start))
    # Save the within cluster sum of squares
    wss[i] <- km_out$tot.withinss
    # bic_inf <- kmeansAIC(km_out)
    # bic[i] <- bic_inf$BIC
    # aic[i] <- bic_inf$AIC
  }
  
  # Produce a scree plot
  wss_df <- tibble(clusters = 1:n_clusters, wss = wss)
   
  scree_plot <- ggplot(wss_df, aes(x = clusters, y = wss, group = 1)) +
      geom_point(size = 4)+
      geom_line() +
      scale_x_continuous(breaks = c(2, 4, 6, 8, 10, 12, 14)) +
      xlab('Number of clusters')
  scree_plot
  
  scree_plot +
      geom_hline(
          yintercept = wss, 
          linetype = 'dashed', 
          col = c(rep('#000000',5),rep('#FF0000', 4), rep('#000000', 5))
      )
  
  
  # # Produce a scree plot using BIC
  # 
  # bic_df <- tibble(clusters = 1:n_clusters, bic = bic)
  #  
  # bic_scree_plot <- ggplot(bic_df, aes(x = clusters, y = bic, group = 1)) +
  #     geom_point(size = 4)+
  #     geom_line() +
  #     scale_x_continuous(breaks = c(2, 4, 6, 8, 10, 12, 14)) +
  #     xlab('Number of clusters')
  # bic_scree_plot
  # 
  # bic_scree_plot +
  #     geom_hline(
  #         yintercept = bic, 
  #         linetype = 'dashed', 
  #         col = c(rep('#000000',4),'#FF0000', rep('#000000', 9))
  #     )
  # 
  # # Produce a scree plot using AIC
  # 
  # aic_df <- tibble(clusters = 1:n_clusters, aic = aic)
  #  
  # aic_scree_plot <- ggplot(aic_df, aes(x = clusters, y = aic, group = 1)) +
  #     geom_point(size = 4)+
  #     geom_line() +
  #     scale_x_continuous(breaks = c(2, 4, 6, 8, 10, 12, 14)) +
  #     xlab('Number of clusters')
  # aic_scree_plot
  # 
  # aic_scree_plot +
  #     geom_hline(
  #         yintercept = aic, 
  #         linetype = 'dashed', 
  #         col = c(rep('#000000',4),'#FF0000', rep('#000000', 9))
  #     )
  # 
}

```

### Cluster analysis

```{r cluster_analysis_cluster_details}

if (opt_analysis_type == 2) {

  set.seed(1)
  (cl_out <- kmeans(x, opt_num_clusters, iter.max=opt_max_iterations, nstart=opt_n_start))
  
  cluster_profile <- t(cl_out$centers)
  cluster_ids <- cl_out$cluster
  
  profile_id <- profile_id %>%
    mutate(cluster = cluster_ids)
  
  # Add cluster to temp_anomaly_va
  temp_anomaly_cluster <- full_join(temp_anomaly_va, profile_id)
  
  # Plot cluster mean
  anomaly_cluster_mean <- temp_anomaly_cluster %>% 
    filter(cluster >= 1) %>%
    group_by(cluster, depth) %>% 
    summarise(count_cluster = n(),
              anomaly_mean = mean(anomaly, na.rm = TRUE),
              anomaly_sd = sd(anomaly, na.rm = TRUE)) %>%
    ungroup()

  # create figure
  anomaly_cluster_mean %>% 
    ggplot()+
    geom_path(aes(x = anomaly_mean,
                  y = depth))+
    geom_ribbon(aes(xmax = anomaly_mean + anomaly_sd,
                    xmin = anomaly_mean - anomaly_sd,
                    y = depth),
                alpha = 0.2)+
    geom_vline(xintercept = 0)+
    scale_y_reverse()+
    facet_wrap(~cluster)+
    coord_cartesian(xlim = opt_xlim)+
    scale_x_continuous(breaks = opt_xbreaks)+
    labs(title = paste0('Overall mean anomaly profiles by cluster'), x = opt_measure_label, y = 'depth (m)')

}

```

### Cluster by year

count of each cluster by year

```{r cluster_by_year}

if (opt_analysis_type == 2) {

  # cluster_profile <- t(cl_out$centers)
  # cluster_ids <- cl_out$cluster
  # 
  # profile_id <- profile_id %>%
  #   mutate(cluster = cluster_ids)
  
  # Add cluster to temp_anomaly_va
  temp_anomaly_by_cluster <- unique(full_join(temp_anomaly_va, profile_id) %>%
                              select (file_id, year, cluster) %>%
                              filter (!is.na(cluster)))
  
  # Determine profile count by cluster and year
  cluster_by_year <- temp_anomaly_by_cluster %>% 
    filter(cluster >= 1) %>%
    group_by(cluster = as.character(cluster), year) %>% 
    summarise(count_cluster = n()) %>%
    ungroup()

  year_min <- min(cluster_by_year$year)
  year_max <- max(cluster_by_year$year)
  
  # create figure
  cluster_by_year %>% 
    ggplot(aes(x = year, y = count_cluster, col = cluster, group=cluster))+
    geom_point() +
    geom_line() +
    scale_x_continuous(breaks = seq(year_min, year_max, 2)) +
    scale_color_brewer(palette = 'Dark2')+
    labs(x = 'year', 
         y = 'number of profiles', 
         col = 'cluster',
         title = 'Count of profiles by year and cluster')

}

```

### Cluster by month

count of each cluster by month of year

```{r cluster_by_month}

if (opt_analysis_type == 2) {

  # cluster_profile <- t(cl_out$centers)
  # cluster_ids <- cl_out$cluster
  # 
  # profile_id <- profile_id %>%
  #   mutate(cluster = cluster_ids)
  
  # Add cluster to temp_anomaly_va
  temp_anomaly_by_cluster <- unique(full_join(temp_anomaly_va, profile_id) %>%
                              select (file_id, month, cluster) %>%
                              filter (!is.na(cluster)))
  
  # Determine profile count by cluster and year
  cluster_by_year <- temp_anomaly_by_cluster %>% 
    filter(cluster >= 1) %>%
    group_by(cluster = as.character(cluster), month) %>% 
    summarise(count_cluster = n()) %>%
    ungroup()

  # create figure
  cluster_by_year %>% 
    ggplot(aes(x = month, y = count_cluster, col = cluster, group=cluster))+
    geom_point() +
    geom_line() +
    scale_x_continuous(breaks = seq(1, 12, 2)) +
    scale_color_brewer(palette = 'Dark2')+
    labs(x = 'month', 
         y = 'number of profiles', 
         col = 'cluster',
         title = 'Count of profiles by month and cluster')

}

```

### Cluster spatial

location of each cluster on map, spatial analysis

```{r spatial_cluster}

if (opt_analysis_type == 2) {

  # cluster_profile <- t(cl_out$centers)
  # cluster_ids <- cl_out$cluster
  # 
  # profile_id <- profile_id %>%
  #   mutate(cluster = cluster_ids)
  
  # Add cluster to temp_anomaly_va
  temp_anomaly_spatial <- unique(full_join(temp_anomaly_va, profile_id) %>%
                              select (file_id, lat, lon, cluster) %>%
                              filter (!is.na(cluster)))
  
  temp_anomaly_spatial <- temp_anomaly_spatial %>% 
                              mutate(cluster = as.character(cluster))
  
  # create figure
map +
  geom_tile(data = temp_anomaly_spatial, 
            aes(x = lon, 
                y = lat, 
                fill = cluster))+
  #lims(y = c(-85, -30))+
  scale_fill_brewer(palette = 'Dark2')+
  labs(title = 'cluster spatial distribution')

  # create figure
map +
  geom_tile(data = temp_anomaly_spatial, 
            aes(x = lon, 
                y = lat, 
                fill = cluster))+
  #lims(y = c(-85, -30))+
  scale_fill_brewer(palette = 'Dark2')+
  facet_wrap(~cluster, ncol = 2) +
  labs(title = 'cluster spatial distribution')

}

```

### Cluster spatial year

location of each cluster on map, spatial analysis by year

```{r spatial_cluster}

if (opt_analysis_type == 2) {

  # cluster_profile <- t(cl_out$centers)
  # cluster_ids <- cl_out$cluster
  # 
  # profile_id <- profile_id %>%
  #   mutate(cluster = cluster_ids)
  
  # Add cluster to temp_anomaly_va
  temp_anomaly_spatial <- unique(full_join(temp_anomaly_va, profile_id) %>%
                              select (file_id, lat, lon, year, cluster) %>%
                              filter (!is.na(cluster)))
  
  temp_anomaly_spatial <- temp_anomaly_spatial %>% 
                              mutate(cluster = as.character(cluster))
  
  # create figure
  temp_anomaly_spatial %>%
    group_split(year) %>% 
map(
  ~map +
  geom_tile(data = .x, 
            aes(x = lon, 
                y = lat, 
                fill = cluster))+
  #lims(y = c(-85, -30))+
  scale_fill_brewer(palette = 'Dark2')+
  facet_wrap(~cluster, ncol = 2) +
  labs(title = paste0('cluster spatial distribution ', unique(.x$year)))
)

}

```
